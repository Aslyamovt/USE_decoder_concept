{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c8f4298813d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "'''\n",
    "from keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "'''\n",
    "\n",
    "'''\n",
    "session1 = tf.Session()\n",
    "with tf.device('/gpu:0'):\n",
    "    config = tf.ConfigProto(intra_op_parallelism_threads=32,\\\n",
    "           inter_op_parallelism_threads=32, allow_soft_placement=True,\\\n",
    "           device_count = {'CPU' : 1, 'GPU' : 1})\n",
    "    session1 = tf.Session(config=config)\n",
    "#K.set_session(session1)\n",
    "session2 = tf.Session()\n",
    "with tf.device('/gpu:1'):\n",
    "    config = tf.ConfigProto(intra_op_parallelism_threads=32,\\\n",
    "           inter_op_parallelism_threads=32, allow_soft_placement=True,\\\n",
    "           device_count = {'CPU' : 1, 'GPU' : 1})\n",
    "    session2 = tf.Session(config=config)\n",
    "'''\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.75)\n",
    ")\n",
    "\n",
    "self.sess = tf.Session(config=config)\n",
    "K.set_session(self.sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with session1.as_default():\n",
    "from keras_transformer import *\n",
    "\n",
    "import numpy as np\n",
    "from keras_layer_normalization import LayerNormalization\n",
    "from keras_multi_head import MultiHeadAttention\n",
    "from keras_position_wise_feed_forward import FeedForward\n",
    "from keras_pos_embd import TrigPosEmbedding\n",
    "from keras_embed_sim import EmbeddingRet, EmbeddingSim\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.layers import Input, Lambda,RepeatVector,Dense,Reshape,Dropout\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "\n",
    "def get_m(token_num,\n",
    "          embed_dim,\n",
    "          encoder_num,\n",
    "          decoder_num,\n",
    "          head_num,\n",
    "          hidden_dim,\n",
    "          attention_activation=None,\n",
    "          feed_forward_activation='relu',\n",
    "          dropout_rate=0.0,\n",
    "          embed_weights =None,\n",
    "          embed_trainable=None,\n",
    "          trainable=True,\n",
    "          use_adapter=False,\n",
    "          adapter_units=None,\n",
    "          adapter_activation='relu'):\n",
    "\n",
    "    decoder_token_num = token_num\n",
    "\n",
    "    decoder_embed_weights = embed_weights\n",
    "\n",
    "    if decoder_embed_weights is not None:\n",
    "        decoder_embed_weights = [decoder_embed_weights]\n",
    "\n",
    "    decoder_embed_trainable = embed_trainable\n",
    "\n",
    "    if decoder_embed_trainable is None:\n",
    "        decoder_embed_trainable = decoder_embed_weights is None\n",
    "\n",
    "\n",
    "    decoder_embed_layer = EmbeddingRet(\n",
    "        input_dim=decoder_token_num,\n",
    "        output_dim=embed_dim,\n",
    "        mask_zero=True,\n",
    "        weights=decoder_embed_weights,\n",
    "        trainable=decoder_embed_trainable,\n",
    "        name='Decoder-Token-Embedding',\n",
    "    )\n",
    "\n",
    "    encoder_input = keras.layers.Input(shape=(None,100), name='Encoder-Input')\n",
    "    pos_wised_encoder = TrigPosEmbedding(\n",
    "        mode=TrigPosEmbedding.MODE_ADD,\n",
    "        name='Encoder-Embedding',\n",
    "    )(encoder_input)\n",
    "    #pos_wised_encoder = Lambda(get_position_encoding, name='Encoder_With_Positions')(encoder_input)\n",
    "\n",
    "    encoded_layer = get_encoders(\n",
    "        encoder_num=encoder_num,\n",
    "        input_layer=pos_wised_encoder,#encoder_input,\n",
    "        head_num=head_num,\n",
    "        hidden_dim=hidden_dim,\n",
    "        attention_activation=attention_activation,\n",
    "        feed_forward_activation=feed_forward_activation,\n",
    "        dropout_rate=dropout_rate,\n",
    "        trainable=trainable,\n",
    "        use_adapter=use_adapter,\n",
    "        adapter_units=adapter_units,\n",
    "        adapter_activation=adapter_activation,\n",
    "    )\n",
    "\n",
    "    decoder_input = keras.layers.Input(shape=(None,), name='Decoder-Input') \n",
    "    decoder_embed, decoder_embed_weights = decoder_embed_layer(decoder_input)\n",
    "    decoder_embed = TrigPosEmbedding(\n",
    "        mode=TrigPosEmbedding.MODE_ADD,\n",
    "        name='Decoder-Embedding',\n",
    "    )(decoder_embed)\n",
    "    decoded_layer = get_decoders(\n",
    "        decoder_num=decoder_num,\n",
    "        input_layer=decoder_embed,\n",
    "        encoded_layer=encoded_layer,\n",
    "        head_num=head_num,\n",
    "        hidden_dim=hidden_dim,\n",
    "        attention_activation=attention_activation,\n",
    "        feed_forward_activation=feed_forward_activation,\n",
    "        dropout_rate=dropout_rate,\n",
    "        trainable=trainable,\n",
    "        use_adapter=use_adapter,\n",
    "        adapter_units=adapter_units,\n",
    "        adapter_activation=adapter_activation,\n",
    "    )\n",
    "    dense_layer = EmbeddingSim(\n",
    "        trainable=trainable,\n",
    "        name='Output',\n",
    "    )([decoded_layer, decoder_embed_weights])\n",
    "    return keras.models.Model(inputs=[encoder_input,decoder_input], outputs=dense_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def piecesextender(data):\n",
    "    kol= np.zeros(shape=(data.shape[0]))\n",
    "    for i in range(data.shape[0]):\n",
    "        kol[i]=np.count_nonzero(data[i])\n",
    "    kol = kol.astype(np.int)\n",
    "    out = np.zeros(shape=(np.sum(kol)-2*kol.shape[0],512))\n",
    "    buf = 0\n",
    "    for g in range(data.shape[0]):        \n",
    "        for k in range(1,kol[g]-1):\n",
    "            out[buf][0]=3000\n",
    "            out[buf][1:513-k]+=data[g][k:]\n",
    "            buf+=1\n",
    "    return out, kol\n",
    "\n",
    "def vectorsextender(data,kol):\n",
    "    out = np.zeros(shape=(np.sum(kol)-2*data.shape[0],512))\n",
    "    buf=0\n",
    "    for g in range(data.shape[0]):\n",
    "        for k in range(kol[g]-2):\n",
    "            out[buf]+=data[g]\n",
    "            buf+=1\n",
    "    return out\n",
    "\n",
    "def positionencoder(kol):\n",
    "    out = np.zeros(shape=(np.sum(kol)-2*kol.shape[0],1))\n",
    "    out = out.astype(np.int)\n",
    "    buf=0\n",
    "    for g in range(len(kol)):\n",
    "        for k in range(1,kol[g]-1):\n",
    "            out[buf]=k\n",
    "            buf+=1\n",
    "    return out\n",
    "\n",
    "def vectors_per_words(vectors,kols):#,model):\n",
    "    from keras.models import load_model\n",
    "    import numpy as np\n",
    "\n",
    "    encoder_shifter_model = load_model('D:/112/decoder/models/sen_to_word2_0.h5')\n",
    "    out = np.zeros(shape=(vectors.shape[0],512,100))\n",
    "    kol = kols.tolist()\n",
    "    #with session2.as_default():\n",
    "    for i in range(vectors.shape[0]):\n",
    "        out[i][kol[i][0]] = np.ones(100)\n",
    "        for k in range(kol[i][0]-1):\n",
    "            out[i][k+1]=encoder_shifter_model.predict(\n",
    "                [vectors[i].reshape(1,512),\n",
    "                 np.array([k+1])])[1]\n",
    "        out[i][kol[i][0]+2:]-= np.ones(shape=(512-kol[i][0]-2,100))\n",
    "        out[i][kol[i][0]+2:]-= np.ones(shape=(512-kol[i][0]-2,100))\n",
    "    np.save('D:/112/decoder/data/buf.npy', out)\n",
    "    #return out \n",
    "    \n",
    "def f(text):\n",
    "    print(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#with session1.as_default():\n",
    "model = get_m(\n",
    "    token_num=3003,\n",
    "    embed_dim=100,\n",
    "    encoder_num=3,\n",
    "    decoder_num=6,\n",
    "    head_num=4,\n",
    "    hidden_dim=120,\n",
    "    attention_activation='relu',\n",
    "    feed_forward_activation='relu',\n",
    "    dropout_rate=0.05,\n",
    "    embed_weights=np.random.random((3003, 100)),\n",
    "    use_adapter=False,\n",
    ")\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    ")\n",
    "#model.save('D:/112/decoder/models/dec_buf.h5')\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('D:/112/decoder/models/dec_buf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "p = Process(target=f, args=('Bob'))\n",
    "p.start()\n",
    "p.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readed\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a8736757ddec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpositionencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvectors_per_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvtt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m#vpwt=vectors_per_words(vtt,pos,encoder_shifter_model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dec2\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dec2\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dec2\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dec2\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dec2\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "from multiprocessing import Process\n",
    "\n",
    "for i in range(1000):\n",
    "    vectors_train = np.load('D:/112/decoder/data/data3000/news_vectors'+str(i)+'.npy')\n",
    "    pieces_train = np.load('D:/112/decoder/data/data3000/news_pieces'+str(i)+'.npy')\n",
    "    shifting = np.ones(shape=(pieces_train.shape[0],512))\n",
    "    pieces_train = pieces_train+shifting\n",
    "    \n",
    "    print('Readed')  \n",
    "        \n",
    "    for j in range(90):\n",
    "        ptt, kol = piecesextender(pieces_train[0+j*5:(1+j)*5])\n",
    "        pot = np.copy(ptt)\n",
    "        pot = shift(pot, (0,-1))\n",
    "        pot = pot.reshape(pot.shape[0],512,1)\n",
    "        vtt = vectorsextender(vectors_train[0+j*5:(1+j)*5], kol)\n",
    "        pos = positionencoder(kol)\n",
    "        p = Process(target=vectors_per_words, args=(vtt,pos))\n",
    "        p.start()\n",
    "        p.join()\n",
    "        #vpwt=vectors_per_words(vtt,pos,encoder_shifter_model)\n",
    "        print('Converted') \n",
    "        \n",
    "        vpwt=np.load('D:/112/decoder/data/buf.npy')\n",
    "        #reset_keras()\n",
    "        #with session1.as_default():\n",
    "        model.train_on_batch(\n",
    "            x=[vpwt,\n",
    "               ptt],\n",
    "            y = pot\n",
    "        )\n",
    "        \n",
    "    ptt, kol = piecesextender(pieces_train[450:])\n",
    "    pot = np.copy(ptt)\n",
    "    pot = shift(pot, (0,-1))\n",
    "    pot = pot.reshape(pot.shape[0],512,1)\n",
    "    vtt = vectorsextender(vectors_train[450:], kol)\n",
    "    pos = positionencoder(kol)        \n",
    "    vpwt=vectors_per_words(vtt,kol, encoder_shifter_model)\n",
    "    #with session1.as_default():\n",
    "    model.test_on_batch(\n",
    "        x=[vpwt,\n",
    "           ptt],\n",
    "        y = pot\n",
    "    )    \n",
    "    model.save('D:/decoder/models/m'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_on_batch() got an unexpected keyword argument 'reset_metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d17f09e93a32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                ptt],\n\u001b[0;32m      4\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m             \u001b[0mreset_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: train_on_batch() got an unexpected keyword argument 'reset_metrics'"
     ]
    }
   ],
   "source": [
    "model.train_on_batch(\n",
    "            x=[vpwt,\n",
    "               ptt],\n",
    "            y = pot,\n",
    "            reset_metrics=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "path=''\n",
    "print(path=='f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
