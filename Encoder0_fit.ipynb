{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y):\n",
    "    from keras import backend as k\n",
    "    return k.one_hot(y, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3492: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Concatenate,Lambda,Reshape,Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "vector = Input(shape=(512,), name='Vectors-Input',dtype='float32')\n",
    "vector_shiter = Dense(512)(vector)\n",
    "position = Input(shape=(1,), name='Positions-Input',dtype='int32')\n",
    "categorical_position=Lambda(to_categorical, name='Positional_encoding')(position)\n",
    "reshaped_categorical_position=Reshape((512,))(categorical_position)\n",
    "concatenated_encoder_input=Concatenate()([vector_shiter,reshaped_categorical_position])\n",
    "encoder_input_divider1 = Dense(1024, name='Encoder-Output-Divider-1',activation='selu')(concatenated_encoder_input)\n",
    "encoder_input_dropout1=Dropout(0.1, name='Encoder-Output-Dropout-1')(encoder_input_divider1)\n",
    "\n",
    "encoder_input_divider2 = Dense(512, name='Encoder-Output-Divider-2',activation='selu')(encoder_input_dropout1)\n",
    "encoder_input_dropout2=Dropout(0.1, name='Encoder-Output-Dropout-2')(encoder_input_divider2)\n",
    "\n",
    "output_vector = Dense(512, name='Encoder-Garbedge',activation='selu')(encoder_input_dropout2)\n",
    "encoder_input_divider3 = Dense(256, name='Encoder-Output-Divider-3',activation='selu')(encoder_input_dropout2)\n",
    "\n",
    "output_vector2 = Dense(100, name='Encoder-Output',activation='selu')(encoder_input_divider3)\n",
    "\n",
    "model = Model(inputs=[vector,position],outputs=[output_vector,output_vector2])\n",
    "#custom_adam=Adam(lr=0.0005)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bpemb import BPEmb\n",
    "from collections import Iterable\n",
    "import numpy as np\n",
    "\n",
    "bpemb_ru = BPEmb(lang=\"ru\", dim=100, vs=3000)\n",
    "\n",
    "def textreader(st):\n",
    "    texts = []\n",
    "    with open(\"D:/112/decoder/Data/data3000/np_rev2.txt\", \"r\", encoding='utf-8') as fr:\n",
    "        i=0\n",
    "        for line in fr:\n",
    "            i+=1\n",
    "            if i<st:      \n",
    "                continue\n",
    "            texts.append(line.replace('\\n',''))\n",
    "            if i==st+499:\n",
    "                break\n",
    "    return texts\n",
    "\n",
    "def word_vectors_creator(data):\n",
    "    l=len(data)\n",
    "    kol= np.zeros(shape=(l))\n",
    "    pieces=[]\n",
    "    for i in range(l):\n",
    "        s = bpemb_ru.encode_ids(data[i])\n",
    "        kol[i]+=len(s)\n",
    "        pieces.append(s)\n",
    "    kol = kol.astype(np.int)\n",
    "    out = np.zeros(shape=(np.sum(kol),100))\n",
    "    #out2 = np.zeros(shape=(np.sum(kol),100))\n",
    "    buf = 0\n",
    "    for g in range(l):        \n",
    "        for k in range(0,kol[g]):\n",
    "            out[buf]+=bpemb_ru.emb.vectors[pieces[g][k]]\n",
    "            '''\n",
    "            for m in range(kol[g]):\n",
    "                if m!=k:\n",
    "                    out2[buf]+=(bpemb_ru.emb.vectors[pieces[g][m]]/kol[g])\n",
    "            buf+=1\n",
    "            '''\n",
    "    return out, kol       #, out2\n",
    "\n",
    "def vectorsextender(data,kol):\n",
    "    out = np.zeros(shape=(np.sum(kol),512))\n",
    "    out2 = np.zeros(shape=(np.sum(kol)))\n",
    "    buf=0\n",
    "    for g in range(data.shape[0]):\n",
    "        for k in range(kol[g]):\n",
    "            out[buf]+=data[g]\n",
    "            #out2[buf]+=np.sum(data[g])/512\n",
    "            buf+=1\n",
    "    return out#, out2\n",
    "\n",
    "def positioncreator(kol):\n",
    "    out = np.zeros(shape=(np.sum(kol)))\n",
    "    buf=0\n",
    "    for g in range(len(kol)):\n",
    "        out[buf:buf+kol[g]]+=np.arange(1,kol[g]+1)\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3492: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model ('D:/112/decoder/models/mse_sen_to_word0_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4578 samples, validate on 241 samples\n",
      "Epoch 521/521\n",
      "4578/4578 [==============================] - 17s 4ms/step - loss: 7.8072 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.7940 - val_loss: 1.9301 - val_Encoder-Garbedge_loss: 0.0138 - val_Encoder-Output_loss: 1.9163\n",
      "Train on 5409 samples, validate on 285 samples\n",
      "Epoch 541/541\n",
      "5409/5409 [==============================] - 21s 4ms/step - loss: 7.8029 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.7898 - val_loss: 1.8076 - val_Encoder-Garbedge_loss: 0.0128 - val_Encoder-Output_loss: 1.7947\n",
      "Train on 3873 samples, validate on 204 samples\n",
      "Epoch 561/561\n",
      "3873/3873 [==============================] - 14s 4ms/step - loss: 6.8133 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 6.8003 - val_loss: 1.7637 - val_Encoder-Garbedge_loss: 0.0120 - val_Encoder-Output_loss: 1.7517\n",
      "Train on 6058 samples, validate on 319 samples\n",
      "Epoch 581/581\n",
      "6058/6058 [==============================] - 22s 4ms/step - loss: 8.3074 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 8.2941 - val_loss: 1.8066 - val_Encoder-Garbedge_loss: 0.0139 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 4282 samples, validate on 226 samples\n",
      "Epoch 601/601\n",
      "4282/4282 [==============================] - 16s 4ms/step - loss: 8.9110 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 8.8976 - val_loss: 1.9907 - val_Encoder-Garbedge_loss: 0.0112 - val_Encoder-Output_loss: 1.9795\n",
      "Train on 4404 samples, validate on 232 samples\n",
      "Epoch 621/621\n",
      "4404/4404 [==============================] - 16s 4ms/step - loss: 8.1762 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 8.1626 - val_loss: 1.1598 - val_Encoder-Garbedge_loss: 0.0121 - val_Encoder-Output_loss: 1.1477\n",
      "Train on 4845 samples, validate on 256 samples\n",
      "Epoch 641/641\n",
      "4845/4845 [==============================] - 18s 4ms/step - loss: 12.5204 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 12.5070 - val_loss: 1.7150 - val_Encoder-Garbedge_loss: 0.0148 - val_Encoder-Output_loss: 1.7002\n",
      "Train on 4103 samples, validate on 216 samples\n",
      "Epoch 661/661\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 7.1542 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 7.1407 - val_loss: 1.7109 - val_Encoder-Garbedge_loss: 0.0109 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4078 samples, validate on 215 samples\n",
      "Epoch 681/681\n",
      "4078/4078 [==============================] - 15s 4ms/step - loss: 8.6154 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 8.6020 - val_loss: 1.7729 - val_Encoder-Garbedge_loss: 0.0111 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 5072 samples, validate on 267 samples\n",
      "Epoch 701/701\n",
      "5072/5072 [==============================] - 19s 4ms/step - loss: 7.7463 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.7330 - val_loss: 1.6511 - val_Encoder-Garbedge_loss: 0.0129 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 3608 samples, validate on 190 samples\n",
      "Epoch 721/721\n",
      "3608/3608 [==============================] - 13s 4ms/step - loss: 7.7871 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.7737 - val_loss: 1.8648 - val_Encoder-Garbedge_loss: 0.0103 - val_Encoder-Output_loss: 1.8545\n",
      "Train on 4101 samples, validate on 216 samples\n",
      "Epoch 741/741\n",
      "4101/4101 [==============================] - 16s 4ms/step - loss: 5.5386 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 5.5253 - val_loss: 1.6848 - val_Encoder-Garbedge_loss: 0.0157 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 3724 samples, validate on 196 samples\n",
      "Epoch 761/761\n",
      "3724/3724 [==============================] - 13s 4ms/step - loss: 7.1886 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.1751 - val_loss: 2.6791 - val_Encoder-Garbedge_loss: 0.0121 - val_Encoder-Output_loss: 2.6670\n",
      "Train on 5636 samples, validate on 297 samples\n",
      "Epoch 781/781\n",
      "5636/5636 [==============================] - 20s 4ms/step - loss: 7.7704 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.7570 - val_loss: 1.7317 - val_Encoder-Garbedge_loss: 0.0134 - val_Encoder-Output_loss: 1.7183\n",
      "Train on 4170 samples, validate on 220 samples\n",
      "Epoch 801/801\n",
      "4170/4170 [==============================] - 15s 4ms/step - loss: 6.8398 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.8265 - val_loss: 1.8078 - val_Encoder-Garbedge_loss: 0.0147 - val_Encoder-Output_loss: 1.7930\n",
      "Train on 4520 samples, validate on 238 samples\n",
      "Epoch 821/821\n",
      "4520/4520 [==============================] - 17s 4ms/step - loss: 7.7271 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.7138 - val_loss: 1.8315 - val_Encoder-Garbedge_loss: 0.0079 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 4821 samples, validate on 254 samples\n",
      "Epoch 841/841\n",
      "4821/4821 [==============================] - 17s 4ms/step - loss: 8.2267 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 8.2136 - val_loss: 1.6843 - val_Encoder-Garbedge_loss: 0.0152 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 4787 samples, validate on 252 samples\n",
      "Epoch 861/861\n",
      "4787/4787 [==============================] - 17s 4ms/step - loss: 8.6598 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 8.6464 - val_loss: 2.0211 - val_Encoder-Garbedge_loss: 0.0120 - val_Encoder-Output_loss: 2.0091\n",
      "Train on 5714 samples, validate on 301 samples\n",
      "Epoch 881/881\n",
      "5714/5714 [==============================] - 25s 4ms/step - loss: 7.2849 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.2716 - val_loss: 11.5077 - val_Encoder-Garbedge_loss: 0.0124 - val_Encoder-Output_loss: 11.4953\n",
      "Train on 3662 samples, validate on 193 samples\n",
      "Epoch 901/901\n",
      "3662/3662 [==============================] - 14s 4ms/step - loss: 7.5939 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.5805 - val_loss: 7.9658 - val_Encoder-Garbedge_loss: 0.0104 - val_Encoder-Output_loss: 7.9554\n",
      "Train on 5016 samples, validate on 264 samples\n",
      "Epoch 921/921\n",
      "5016/5016 [==============================] - 19s 4ms/step - loss: 7.2696 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.2563 - val_loss: 1.7108 - val_Encoder-Garbedge_loss: 0.0108 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4517 samples, validate on 238 samples\n",
      "Epoch 941/941\n",
      "4517/4517 [==============================] - 18s 4ms/step - loss: 8.2673 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 8.2541 - val_loss: 1.8404 - val_Encoder-Garbedge_loss: 0.0169 - val_Encoder-Output_loss: 1.8235\n",
      "Train on 4483 samples, validate on 236 samples\n",
      "Epoch 961/961\n",
      "4483/4483 [==============================] - 18s 4ms/step - loss: 6.7033 - Encoder-Garbedge_loss: 0.0139 - Encoder-Output_loss: 6.6894 - val_loss: 1.6192 - val_Encoder-Garbedge_loss: 0.0118 - val_Encoder-Output_loss: 1.6074\n",
      "Train on 4614 samples, validate on 243 samples\n",
      "Epoch 981/981\n",
      "4614/4614 [==============================] - 18s 4ms/step - loss: 8.7447 - Encoder-Garbedge_loss: 0.0138 - Encoder-Output_loss: 8.7309 - val_loss: 1.6822 - val_Encoder-Garbedge_loss: 0.0128 - val_Encoder-Output_loss: 1.6694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "start=1\n",
    "n=501\n",
    "e=502\n",
    "for i in range(101,200):\n",
    "    vectors_train = np.load('D:/112/decoder/Data/data3000/news_vectors'+str(999-i)+'.npy')\n",
    "    #print(start)\n",
    "    texts = textreader(start)\n",
    "    start+=500\n",
    "    #print(len(texts))\n",
    "\n",
    "    for j in range(5):\n",
    "        tt, kol  = word_vectors_creator(texts[0+j*100:(1+j)*100])\n",
    "        vtt = vectorsextender(vectors_train[0+j*100:(1+j)*100], kol)\n",
    "        pos = positioncreator(kol)\n",
    "        tt, vtt,pos = shuffle(tt, vtt,pos, random_state=0)\n",
    "\n",
    "        if n%20==0:\n",
    "            model.fit(\n",
    "                x=[vtt,\n",
    "                   pos],\n",
    "                y = [vtt,\n",
    "                    tt],\n",
    "                epochs=e, initial_epoch=n,\n",
    "                validation_split=0.05,\n",
    "                verbose=1,\n",
    "                batch_size=4\n",
    "            )\n",
    "            if n%500==0:\n",
    "                model.save('D:/112/decoder/models/mse_sen_to_word'+str(d)+'_'+str(i)+'.h5')\n",
    "                print('\\n')\n",
    "        else:\n",
    "            model.fit(\n",
    "                x=[vtt,\n",
    "                   pos],\n",
    "                y = [vtt,\n",
    "                    tt],\n",
    "                epochs=e, initial_epoch=n,\n",
    "                validation_split=0.05,\n",
    "                verbose=0,\n",
    "                batch_size=4\n",
    "            )\n",
    "        n+=1\n",
    "        e+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "**********************************\n",
      "\n",
      "Train on 4323 samples, validate on 228 samples\n",
      "Epoch 1001/1001\n",
      "4323/4323 [==============================] - 18s 4ms/step - loss: 6.7881 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.7749 - val_loss: 1.7102 - val_Encoder-Garbedge_loss: 0.0102 - val_Encoder-Output_loss: 1.7000\n",
      "\n",
      "\n",
      "Train on 2870 samples, validate on 152 samples\n",
      "Epoch 1021/1021\n",
      "2870/2870 [==============================] - 12s 4ms/step - loss: 10.4405 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 10.4275 - val_loss: 1.8683 - val_Encoder-Garbedge_loss: 0.0138 - val_Encoder-Output_loss: 1.8545\n",
      "Train on 5088 samples, validate on 268 samples\n",
      "Epoch 1041/1041\n",
      "5088/5088 [==============================] - 20s 4ms/step - loss: 7.5186 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.5051 - val_loss: 1.7735 - val_Encoder-Garbedge_loss: 0.0117 - val_Encoder-Output_loss: 1.7617\n",
      "Train on 4287 samples, validate on 226 samples\n",
      "Epoch 1061/1061\n",
      "4287/4287 [==============================] - 17s 4ms/step - loss: 9.4548 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 9.4412 - val_loss: 1.6810 - val_Encoder-Garbedge_loss: 0.0119 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 3027 samples, validate on 160 samples\n",
      "Epoch 1081/1081\n",
      "3027/3027 [==============================] - 12s 4ms/step - loss: 8.0988 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 8.0854 - val_loss: 1.8337 - val_Encoder-Garbedge_loss: 0.0101 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 4067 samples, validate on 215 samples\n",
      "Epoch 1101/1101\n",
      "4067/4067 [==============================] - 16s 4ms/step - loss: 7.3011 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.2880 - val_loss: 1.7123 - val_Encoder-Garbedge_loss: 0.0123 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 5628 samples, validate on 297 samples\n",
      "Epoch 1121/1121\n",
      "5628/5628 [==============================] - 23s 4ms/step - loss: 8.1363 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 8.1229 - val_loss: 1.8341 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 4883 samples, validate on 257 samples\n",
      "Epoch 1141/1141\n",
      "4883/4883 [==============================] - 20s 4ms/step - loss: 7.8538 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.8407 - val_loss: 1.9298 - val_Encoder-Garbedge_loss: 0.0135 - val_Encoder-Output_loss: 1.9163\n",
      "Train on 4391 samples, validate on 232 samples\n",
      "Epoch 1161/1161\n",
      "4391/4391 [==============================] - 17s 4ms/step - loss: 5.7232 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 5.7098 - val_loss: 1.6821 - val_Encoder-Garbedge_loss: 0.0130 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 5474 samples, validate on 289 samples\n",
      "Epoch 1181/1181\n",
      "5474/5474 [==============================] - 22s 4ms/step - loss: 7.1455 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.1323 - val_loss: 4.2579 - val_Encoder-Garbedge_loss: 0.0134 - val_Encoder-Output_loss: 4.2445\n",
      "Train on 4681 samples, validate on 247 samples\n",
      "Epoch 1201/1201\n",
      "4681/4681 [==============================] - 18s 4ms/step - loss: 6.3427 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.3294 - val_loss: 1.7782 - val_Encoder-Garbedge_loss: 0.0164 - val_Encoder-Output_loss: 1.7617\n",
      "Train on 4414 samples, validate on 233 samples\n",
      "Epoch 1221/1221\n",
      "4414/4414 [==============================] - 17s 4ms/step - loss: 7.5757 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.5625 - val_loss: 1.7096 - val_Encoder-Garbedge_loss: 0.0096 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 6049 samples, validate on 319 samples\n",
      "Epoch 1241/1241\n",
      "6049/6049 [==============================] - 24s 4ms/step - loss: 8.4345 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 8.4212 - val_loss: 1.8423 - val_Encoder-Garbedge_loss: 0.0187 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 4440 samples, validate on 234 samples\n",
      "Epoch 1261/1261\n",
      "4440/4440 [==============================] - 17s 4ms/step - loss: 6.3638 - Encoder-Garbedge_loss: 0.0138 - Encoder-Output_loss: 6.3500 - val_loss: 1.7103 - val_Encoder-Garbedge_loss: 0.0103 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4445 samples, validate on 234 samples\n",
      "Epoch 1281/1281\n",
      "4445/4445 [==============================] - 18s 4ms/step - loss: 7.5489 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.5356 - val_loss: 1.8139 - val_Encoder-Garbedge_loss: 0.0197 - val_Encoder-Output_loss: 1.7942\n",
      "Train on 4634 samples, validate on 244 samples\n",
      "Epoch 1301/1301\n",
      "4634/4634 [==============================] - 19s 4ms/step - loss: 7.2354 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.2222 - val_loss: 2.8928 - val_Encoder-Garbedge_loss: 0.0130 - val_Encoder-Output_loss: 2.8798\n",
      "Train on 3845 samples, validate on 203 samples\n",
      "Epoch 1321/1321\n",
      "3845/3845 [==============================] - 16s 4ms/step - loss: 6.8573 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 6.8437 - val_loss: 1.8380 - val_Encoder-Garbedge_loss: 0.0156 - val_Encoder-Output_loss: 1.8224\n",
      "Train on 4028 samples, validate on 212 samples\n",
      "Epoch 1341/1341\n",
      "4028/4028 [==============================] - 16s 4ms/step - loss: 8.0987 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 8.0858 - val_loss: 1.7439 - val_Encoder-Garbedge_loss: 0.0130 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 1936 samples, validate on 102 samples\n",
      "Epoch 1361/1361\n",
      "1936/1936 [==============================] - 8s 4ms/step - loss: 10.9614 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 10.9480 - val_loss: 2.1659 - val_Encoder-Garbedge_loss: 0.0102 - val_Encoder-Output_loss: 2.1557\n",
      "Train on 4712 samples, validate on 249 samples\n",
      "Epoch 1381/1381\n",
      "4712/4712 [==============================] - 19s 4ms/step - loss: 6.9527 - Encoder-Garbedge_loss: 0.0126 - Encoder-Output_loss: 6.9401 - val_loss: 1.7696 - val_Encoder-Garbedge_loss: 0.0079 - val_Encoder-Output_loss: 1.7617\n",
      "Train on 4750 samples, validate on 251 samples\n",
      "Epoch 1401/1401\n",
      "4750/4750 [==============================] - 20s 4ms/step - loss: 8.0048 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.9913 - val_loss: 1.7126 - val_Encoder-Garbedge_loss: 0.0126 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 5252 samples, validate on 277 samples\n",
      "Epoch 1421/1421\n",
      "5252/5252 [==============================] - 21s 4ms/step - loss: 6.0962 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.0828 - val_loss: 2.1053 - val_Encoder-Garbedge_loss: 0.0106 - val_Encoder-Output_loss: 2.0947\n",
      "Train on 4396 samples, validate on 232 samples\n",
      "Epoch 1441/1441\n",
      "4396/4396 [==============================] - 18s 4ms/step - loss: 6.8242 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.8110 - val_loss: 1.7456 - val_Encoder-Garbedge_loss: 0.0147 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 4576 samples, validate on 241 samples\n",
      "Epoch 1461/1461\n",
      "4576/4576 [==============================] - 18s 4ms/step - loss: 7.1016 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.0883 - val_loss: 2.6839 - val_Encoder-Garbedge_loss: 0.0126 - val_Encoder-Output_loss: 2.6713\n",
      "Train on 5312 samples, validate on 280 samples\n",
      "Epoch 1481/1481\n",
      "5312/5312 [==============================] - 21s 4ms/step - loss: 6.1520 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.1385 - val_loss: 1.7414 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 5139 samples, validate on 271 samples\n",
      "Epoch 1501/1501\n",
      "5139/5139 [==============================] - 21s 4ms/step - loss: 9.2658 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 9.2526 - val_loss: 1.9890 - val_Encoder-Garbedge_loss: 0.0107 - val_Encoder-Output_loss: 1.9783\n",
      "\n",
      "\n",
      "Train on 3935 samples, validate on 208 samples\n",
      "Epoch 1521/1521\n",
      "3935/3935 [==============================] - 15s 4ms/step - loss: 6.9878 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 6.9748 - val_loss: 1.8963 - val_Encoder-Garbedge_loss: 0.0109 - val_Encoder-Output_loss: 1.8854\n",
      "Train on 4031 samples, validate on 213 samples\n",
      "Epoch 1541/1541\n",
      "4031/4031 [==============================] - 16s 4ms/step - loss: 7.2283 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 7.2153 - val_loss: 1.8050 - val_Encoder-Garbedge_loss: 0.0124 - val_Encoder-Output_loss: 1.7926\n",
      "Train on 3729 samples, validate on 197 samples\n",
      "Epoch 1561/1561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3729/3729 [==============================] - 15s 4ms/step - loss: 6.6796 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.6663 - val_loss: 1.9029 - val_Encoder-Garbedge_loss: 0.0176 - val_Encoder-Output_loss: 1.8853\n",
      "Train on 4362 samples, validate on 230 samples\n",
      "Epoch 1581/1581\n",
      "4362/4362 [==============================] - 17s 4ms/step - loss: 7.6802 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.6667 - val_loss: 1.8991 - val_Encoder-Garbedge_loss: 0.0137 - val_Encoder-Output_loss: 1.8855\n",
      "Train on 3657 samples, validate on 193 samples\n",
      "Epoch 1601/1601\n",
      "3657/3657 [==============================] - 14s 4ms/step - loss: 8.9883 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 8.9746 - val_loss: 1.7802 - val_Encoder-Garbedge_loss: 0.0184 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4241 samples, validate on 224 samples\n",
      "Epoch 1621/1621\n",
      "4241/4241 [==============================] - 17s 4ms/step - loss: 6.8969 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.8834 - val_loss: 1.8367 - val_Encoder-Garbedge_loss: 0.0131 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 2373 samples, validate on 125 samples\n",
      "Epoch 1641/1641\n",
      "2373/2373 [==============================] - 10s 4ms/step - loss: 5.3725 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 5.3593 - val_loss: 1.6543 - val_Encoder-Garbedge_loss: 0.0169 - val_Encoder-Output_loss: 1.6374\n",
      "Train on 4390 samples, validate on 232 samples\n",
      "Epoch 1661/1661\n",
      "4390/4390 [==============================] - 17s 4ms/step - loss: 7.6251 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.6120 - val_loss: 1.7124 - val_Encoder-Garbedge_loss: 0.0124 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4099 samples, validate on 216 samples\n",
      "Epoch 1681/1681\n",
      "4099/4099 [==============================] - 16s 4ms/step - loss: 7.5723 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.5589 - val_loss: 1.7352 - val_Encoder-Garbedge_loss: 0.0113 - val_Encoder-Output_loss: 1.7239\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 1701/1701\n",
      "4006/4006 [==============================] - 15s 4ms/step - loss: 9.1613 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 9.1479 - val_loss: 1.7418 - val_Encoder-Garbedge_loss: 0.0110 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 4707 samples, validate on 248 samples\n",
      "Epoch 1721/1721\n",
      "4707/4707 [==============================] - 19s 4ms/step - loss: 6.4741 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 6.4604 - val_loss: 1.6844 - val_Encoder-Garbedge_loss: 0.0153 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 2228 samples, validate on 118 samples\n",
      "Epoch 1741/1741\n",
      "2228/2228 [==============================] - 8s 4ms/step - loss: 9.5791 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 9.5660 - val_loss: 1.8353 - val_Encoder-Garbedge_loss: 0.0109 - val_Encoder-Output_loss: 1.8244\n",
      "Train on 4584 samples, validate on 242 samples\n",
      "Epoch 1761/1761\n",
      "4584/4584 [==============================] - 18s 4ms/step - loss: 6.6108 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.5975 - val_loss: 1.7102 - val_Encoder-Garbedge_loss: 0.0102 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4290 samples, validate on 226 samples\n",
      "Epoch 1781/1781\n",
      "4290/4290 [==============================] - 16s 4ms/step - loss: 7.1765 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.1633 - val_loss: 2.1493 - val_Encoder-Garbedge_loss: 0.0166 - val_Encoder-Output_loss: 2.1327\n",
      "Train on 3598 samples, validate on 190 samples\n",
      "Epoch 1801/1801\n",
      "3598/3598 [==============================] - 14s 4ms/step - loss: 6.6800 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 6.6669 - val_loss: 1.8663 - val_Encoder-Garbedge_loss: 0.0117 - val_Encoder-Output_loss: 1.8546\n",
      "Train on 4768 samples, validate on 251 samples\n",
      "Epoch 1821/1821\n",
      "4768/4768 [==============================] - 18s 4ms/step - loss: 7.2163 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.2030 - val_loss: 1.9279 - val_Encoder-Garbedge_loss: 0.0115 - val_Encoder-Output_loss: 1.9164\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 1841/1841\n",
      "4006/4006 [==============================] - 16s 4ms/step - loss: 8.9807 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 8.9677 - val_loss: 1.5687 - val_Encoder-Garbedge_loss: 0.0165 - val_Encoder-Output_loss: 1.5523\n",
      "Train on 3825 samples, validate on 202 samples\n",
      "Epoch 1861/1861\n",
      "3825/3825 [==============================] - 15s 4ms/step - loss: 7.6866 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.6732 - val_loss: 1.7141 - val_Encoder-Garbedge_loss: 0.0141 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 5114 samples, validate on 270 samples\n",
      "Epoch 1881/1881\n",
      "5114/5114 [==============================] - 20s 4ms/step - loss: 7.5932 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.5800 - val_loss: 1.8682 - val_Encoder-Garbedge_loss: 0.0137 - val_Encoder-Output_loss: 1.8545\n",
      "Train on 4485 samples, validate on 237 samples\n",
      "Epoch 1901/1901\n",
      "4485/4485 [==============================] - 18s 4ms/step - loss: 7.0864 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.0733 - val_loss: 1.7173 - val_Encoder-Garbedge_loss: 0.0173 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 5190 samples, validate on 274 samples\n",
      "Epoch 1921/1921\n",
      "5190/5190 [==============================] - 21s 4ms/step - loss: 7.2496 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.2363 - val_loss: 2.5096 - val_Encoder-Garbedge_loss: 0.0143 - val_Encoder-Output_loss: 2.4953\n",
      "Train on 3797 samples, validate on 200 samples\n",
      "Epoch 1941/1941\n",
      "3797/3797 [==============================] - 15s 4ms/step - loss: 5.9865 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 5.9732 - val_loss: 1.7460 - val_Encoder-Garbedge_loss: 0.0151 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 4964 samples, validate on 262 samples\n",
      "Epoch 1961/1961\n",
      "4964/4964 [==============================] - 20s 4ms/step - loss: 5.6714 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 5.6581 - val_loss: 2.4306 - val_Encoder-Garbedge_loss: 0.0112 - val_Encoder-Output_loss: 2.4195\n",
      "Train on 5469 samples, validate on 288 samples\n",
      "Epoch 1981/1981\n",
      "5469/5469 [==============================] - 21s 4ms/step - loss: 7.0430 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.0297 - val_loss: 2.3541 - val_Encoder-Garbedge_loss: 0.0158 - val_Encoder-Output_loss: 2.3383\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "**********************************\n",
      "\n",
      "Train on 4323 samples, validate on 228 samples\n",
      "Epoch 2001/2001\n",
      "4323/4323 [==============================] - 17s 4ms/step - loss: 6.8868 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.8733 - val_loss: 1.8652 - val_Encoder-Garbedge_loss: 0.0107 - val_Encoder-Output_loss: 1.8545\n",
      "\n",
      "\n",
      "Train on 2870 samples, validate on 152 samples\n",
      "Epoch 2021/2021\n",
      "2870/2870 [==============================] - 11s 4ms/step - loss: 10.4825 - Encoder-Garbedge_loss: 0.0139 - Encoder-Output_loss: 10.4686 - val_loss: 1.9649 - val_Encoder-Garbedge_loss: 0.0179 - val_Encoder-Output_loss: 1.9470\n",
      "Train on 5088 samples, validate on 268 samples\n",
      "Epoch 2041/2041\n",
      "5088/5088 [==============================] - 20s 4ms/step - loss: 7.5864 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.5730 - val_loss: 1.8043 - val_Encoder-Garbedge_loss: 0.0116 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 4287 samples, validate on 226 samples\n",
      "Epoch 2061/2061\n",
      "4287/4287 [==============================] - 17s 4ms/step - loss: 9.3739 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 9.3606 - val_loss: 1.5643 - val_Encoder-Garbedge_loss: 0.0114 - val_Encoder-Output_loss: 1.5529\n",
      "Train on 3027 samples, validate on 160 samples\n",
      "Epoch 2081/2081\n",
      "3027/3027 [==============================] - 12s 4ms/step - loss: 8.1730 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 8.1597 - val_loss: 1.8974 - val_Encoder-Garbedge_loss: 0.0120 - val_Encoder-Output_loss: 1.8854\n",
      "Train on 4067 samples, validate on 215 samples\n",
      "Epoch 2101/2101\n",
      "4067/4067 [==============================] - 16s 4ms/step - loss: 7.1210 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 7.1080 - val_loss: 1.6194 - val_Encoder-Garbedge_loss: 0.0122 - val_Encoder-Output_loss: 1.6072\n",
      "Train on 5628 samples, validate on 297 samples\n",
      "Epoch 2121/2121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5628/5628 [==============================] - 22s 4ms/step - loss: 8.0676 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 8.0542 - val_loss: 1.6816 - val_Encoder-Garbedge_loss: 0.0125 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 4883 samples, validate on 257 samples\n",
      "Epoch 2141/2141\n",
      "4883/4883 [==============================] - 19s 4ms/step - loss: 7.7098 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.6964 - val_loss: 1.7436 - val_Encoder-Garbedge_loss: 0.0127 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 4391 samples, validate on 232 samples\n",
      "Epoch 2161/2161\n",
      "4391/4391 [==============================] - 17s 4ms/step - loss: 5.7956 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 5.7823 - val_loss: 1.7096 - val_Encoder-Garbedge_loss: 0.0097 - val_Encoder-Output_loss: 1.6999\n",
      "Train on 5474 samples, validate on 289 samples\n",
      "Epoch 2181/2181\n",
      "5474/5474 [==============================] - 21s 4ms/step - loss: 7.1513 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.1380 - val_loss: 1.4962 - val_Encoder-Garbedge_loss: 0.0125 - val_Encoder-Output_loss: 1.4836\n",
      "Train on 4681 samples, validate on 247 samples\n",
      "Epoch 2201/2201\n",
      "4681/4681 [==============================] - 18s 4ms/step - loss: 6.3797 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.3663 - val_loss: 1.7759 - val_Encoder-Garbedge_loss: 0.0141 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4414 samples, validate on 233 samples\n",
      "Epoch 2221/2221\n",
      "4414/4414 [==============================] - 17s 4ms/step - loss: 7.5709 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.5577 - val_loss: 1.7419 - val_Encoder-Garbedge_loss: 0.0110 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 6049 samples, validate on 319 samples\n",
      "Epoch 2241/2241\n",
      "6049/6049 [==============================] - 23s 4ms/step - loss: 8.3815 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 8.3679 - val_loss: 1.6859 - val_Encoder-Garbedge_loss: 0.0167 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 4440 samples, validate on 234 samples\n",
      "Epoch 2261/2261\n",
      "4440/4440 [==============================] - 17s 4ms/step - loss: 6.3866 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.3731 - val_loss: 1.7411 - val_Encoder-Garbedge_loss: 0.0103 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 4445 samples, validate on 234 samples\n",
      "Epoch 2281/2281\n",
      "4445/4445 [==============================] - 18s 4ms/step - loss: 7.4757 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.4624 - val_loss: 1.9325 - val_Encoder-Garbedge_loss: 0.0162 - val_Encoder-Output_loss: 1.9163\n",
      "Train on 4634 samples, validate on 244 samples\n",
      "Epoch 2301/2301\n",
      "4634/4634 [==============================] - 18s 4ms/step - loss: 7.1817 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.1683 - val_loss: 1.7419 - val_Encoder-Garbedge_loss: 0.0110 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 3845 samples, validate on 203 samples\n",
      "Epoch 2321/2321\n",
      "3845/3845 [==============================] - 15s 4ms/step - loss: 6.9184 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.9050 - val_loss: 1.8735 - val_Encoder-Garbedge_loss: 0.0189 - val_Encoder-Output_loss: 1.8545\n",
      "Train on 4028 samples, validate on 212 samples\n",
      "Epoch 2341/2341\n",
      "4028/4028 [==============================] - 15s 4ms/step - loss: 8.1218 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 8.1084 - val_loss: 1.7724 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 1936 samples, validate on 102 samples\n",
      "Epoch 2361/2361\n",
      "1936/1936 [==============================] - 7s 4ms/step - loss: 10.7784 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 10.7650 - val_loss: 2.0288 - val_Encoder-Garbedge_loss: 0.0106 - val_Encoder-Output_loss: 2.0182\n",
      "Train on 4712 samples, validate on 249 samples\n",
      "Epoch 2381/2381\n",
      "4712/4712 [==============================] - 19s 4ms/step - loss: 6.9557 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.9425 - val_loss: 1.7410 - val_Encoder-Garbedge_loss: 0.0106 - val_Encoder-Output_loss: 1.7304\n",
      "Train on 4750 samples, validate on 251 samples\n",
      "Epoch 2401/2401\n",
      "4750/4750 [==============================] - 19s 4ms/step - loss: 8.0541 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 8.0404 - val_loss: 1.7156 - val_Encoder-Garbedge_loss: 0.0133 - val_Encoder-Output_loss: 1.7023\n",
      "Train on 5252 samples, validate on 277 samples\n",
      "Epoch 2421/2421\n",
      "5252/5252 [==============================] - 21s 4ms/step - loss: 6.1740 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 6.1609 - val_loss: 1.7753 - val_Encoder-Garbedge_loss: 0.0112 - val_Encoder-Output_loss: 1.7642\n",
      "Train on 4396 samples, validate on 232 samples\n",
      "Epoch 2441/2441\n",
      "4396/4396 [==============================] - 17s 4ms/step - loss: 6.8983 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 6.8847 - val_loss: 1.8079 - val_Encoder-Garbedge_loss: 0.0096 - val_Encoder-Output_loss: 1.7983\n",
      "Train on 4576 samples, validate on 241 samples\n",
      "Epoch 2461/2461\n",
      "4576/4576 [==============================] - 18s 4ms/step - loss: 7.1132 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.0998 - val_loss: 1.7427 - val_Encoder-Garbedge_loss: 0.0117 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 5312 samples, validate on 280 samples\n",
      "Epoch 2481/2481\n",
      "5312/5312 [==============================] - 20s 4ms/step - loss: 6.1414 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.1280 - val_loss: 1.6505 - val_Encoder-Garbedge_loss: 0.0123 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 5139 samples, validate on 271 samples\n",
      "Epoch 2501/2501\n",
      "5139/5139 [==============================] - 20s 4ms/step - loss: 9.2681 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 9.2546 - val_loss: 1.9264 - val_Encoder-Garbedge_loss: 0.0100 - val_Encoder-Output_loss: 1.9165\n",
      "\n",
      "\n",
      "Train on 3935 samples, validate on 208 samples\n",
      "Epoch 2521/2521\n",
      "3935/3935 [==============================] - 15s 4ms/step - loss: 6.9653 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.9517 - val_loss: 1.8985 - val_Encoder-Garbedge_loss: 0.0130 - val_Encoder-Output_loss: 1.8855\n",
      "Train on 4031 samples, validate on 213 samples\n",
      "Epoch 2541/2541\n",
      "4031/4031 [==============================] - 16s 4ms/step - loss: 7.2105 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.1973 - val_loss: 1.7735 - val_Encoder-Garbedge_loss: 0.0121 - val_Encoder-Output_loss: 1.7614\n",
      "Train on 3729 samples, validate on 197 samples\n",
      "Epoch 2561/2561\n",
      "3729/3729 [==============================] - 14s 4ms/step - loss: 6.5599 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 6.5462 - val_loss: 1.7768 - val_Encoder-Garbedge_loss: 0.0152 - val_Encoder-Output_loss: 1.7615\n",
      "Train on 4362 samples, validate on 230 samples\n",
      "Epoch 2581/2581\n",
      "4362/4362 [==============================] - 18s 4ms/step - loss: 7.5139 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.5006 - val_loss: 1.7453 - val_Encoder-Garbedge_loss: 0.0134 - val_Encoder-Output_loss: 1.7320\n",
      "Train on 3657 samples, validate on 193 samples\n",
      "Epoch 2601/2601\n",
      "3657/3657 [==============================] - 15s 4ms/step - loss: 9.0709 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 9.0576 - val_loss: 2.6082 - val_Encoder-Garbedge_loss: 0.0175 - val_Encoder-Output_loss: 2.5907\n",
      "Train on 4241 samples, validate on 224 samples\n",
      "Epoch 2621/2621\n",
      "4241/4241 [==============================] - 17s 4ms/step - loss: 6.8674 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.8539 - val_loss: 1.7488 - val_Encoder-Garbedge_loss: 0.0142 - val_Encoder-Output_loss: 1.7346\n",
      "Train on 2373 samples, validate on 125 samples\n",
      "Epoch 2641/2641\n",
      "2373/2373 [==============================] - 10s 4ms/step - loss: 5.4188 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 5.4055 - val_loss: 1.7110 - val_Encoder-Garbedge_loss: 0.0110 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4390 samples, validate on 232 samples\n",
      "Epoch 2661/2661\n",
      "4390/4390 [==============================] - 18s 4ms/step - loss: 7.4242 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.4109 - val_loss: 6.2884 - val_Encoder-Garbedge_loss: 0.0124 - val_Encoder-Output_loss: 6.2760\n",
      "Train on 4099 samples, validate on 216 samples\n",
      "Epoch 2681/2681\n",
      "4099/4099 [==============================] - 19s 5ms/step - loss: 7.6974 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.6840 - val_loss: 1.8048 - val_Encoder-Garbedge_loss: 0.0121 - val_Encoder-Output_loss: 1.7927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 2701/2701\n",
      "4006/4006 [==============================] - 15s 4ms/step - loss: 9.1494 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 9.1362 - val_loss: 1.7141 - val_Encoder-Garbedge_loss: 0.0141 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4707 samples, validate on 248 samples\n",
      "Epoch 2721/2721\n",
      "4707/4707 [==============================] - 17s 4ms/step - loss: 6.5053 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.4919 - val_loss: 2.2086 - val_Encoder-Garbedge_loss: 0.0112 - val_Encoder-Output_loss: 2.1974\n",
      "Train on 2228 samples, validate on 118 samples\n",
      "Epoch 2741/2741\n",
      "2228/2228 [==============================] - 9s 4ms/step - loss: 9.4222 - Encoder-Garbedge_loss: 0.0141 - Encoder-Output_loss: 9.4080 - val_loss: 1.7130 - val_Encoder-Garbedge_loss: 0.0131 - val_Encoder-Output_loss: 1.6999\n",
      "Train on 4584 samples, validate on 242 samples\n",
      "Epoch 2761/2761\n",
      "4584/4584 [==============================] - 17s 4ms/step - loss: 6.5923 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.5790 - val_loss: 1.6191 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 1.6086\n",
      "Train on 4290 samples, validate on 226 samples\n",
      "Epoch 2781/2781\n",
      "4290/4290 [==============================] - 16s 4ms/step - loss: 7.0377 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 7.0241 - val_loss: 2.0221 - val_Encoder-Garbedge_loss: 0.0130 - val_Encoder-Output_loss: 2.0091\n",
      "Train on 3598 samples, validate on 190 samples\n",
      "Epoch 2801/2801\n",
      "3598/3598 [==============================] - 13s 4ms/step - loss: 6.6958 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 6.6823 - val_loss: 1.9342 - val_Encoder-Garbedge_loss: 0.0178 - val_Encoder-Output_loss: 1.9164\n",
      "Train on 4768 samples, validate on 251 samples\n",
      "Epoch 2821/2821\n",
      "4768/4768 [==============================] - 18s 4ms/step - loss: 7.1755 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.1621 - val_loss: 1.9592 - val_Encoder-Garbedge_loss: 0.0119 - val_Encoder-Output_loss: 1.9473\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 2841/2841\n",
      "4006/4006 [==============================] - 15s 4ms/step - loss: 8.9598 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 8.9469 - val_loss: 1.5595 - val_Encoder-Garbedge_loss: 0.0140 - val_Encoder-Output_loss: 1.5454\n",
      "Train on 3825 samples, validate on 202 samples\n",
      "Epoch 2861/2861\n",
      "3825/3825 [==============================] - 14s 4ms/step - loss: 7.6841 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.6708 - val_loss: 1.7127 - val_Encoder-Garbedge_loss: 0.0127 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 5114 samples, validate on 270 samples\n",
      "Epoch 2881/2881\n",
      "5114/5114 [==============================] - 19s 4ms/step - loss: 7.7128 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.6997 - val_loss: 1.8842 - val_Encoder-Garbedge_loss: 0.0127 - val_Encoder-Output_loss: 1.8715\n",
      "Train on 4485 samples, validate on 237 samples\n",
      "Epoch 2901/2901\n",
      "4485/4485 [==============================] - 17s 4ms/step - loss: 7.0126 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.9992 - val_loss: 1.5914 - val_Encoder-Garbedge_loss: 0.0150 - val_Encoder-Output_loss: 1.5764\n",
      "Train on 5190 samples, validate on 274 samples\n",
      "Epoch 2921/2921\n",
      "5190/5190 [==============================] - 19s 4ms/step - loss: 7.1192 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.1057 - val_loss: 1.7123 - val_Encoder-Garbedge_loss: 0.0123 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 3797 samples, validate on 200 samples\n",
      "Epoch 2941/2941\n",
      "3797/3797 [==============================] - 14s 4ms/step - loss: 5.8081 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 5.7947 - val_loss: 1.5274 - val_Encoder-Garbedge_loss: 0.0129 - val_Encoder-Output_loss: 1.5145\n",
      "Train on 4964 samples, validate on 262 samples\n",
      "Epoch 2961/2961\n",
      "4964/4964 [==============================] - 18s 4ms/step - loss: 5.7028 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 5.6893 - val_loss: 1.9581 - val_Encoder-Garbedge_loss: 0.0114 - val_Encoder-Output_loss: 1.9467\n",
      "Train on 5469 samples, validate on 288 samples\n",
      "Epoch 2981/2981\n",
      "5469/5469 [==============================] - 21s 4ms/step - loss: 6.8776 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.8644 - val_loss: 1.8386 - val_Encoder-Garbedge_loss: 0.0150 - val_Encoder-Output_loss: 1.8236\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "**********************************\n",
      "\n",
      "Train on 4323 samples, validate on 228 samples\n",
      "Epoch 3001/3001\n",
      "4323/4323 [==============================] - 16s 4ms/step - loss: 6.7968 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.7836 - val_loss: 1.7770 - val_Encoder-Garbedge_loss: 0.0152 - val_Encoder-Output_loss: 1.7618\n",
      "\n",
      "\n",
      "Train on 2870 samples, validate on 152 samples\n",
      "Epoch 3021/3021\n",
      "2870/2870 [==============================] - 11s 4ms/step - loss: 10.2886 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 10.2752 - val_loss: 1.7453 - val_Encoder-Garbedge_loss: 0.0144 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 5088 samples, validate on 268 samples\n",
      "Epoch 3041/3041\n",
      "5088/5088 [==============================] - 19s 4ms/step - loss: 7.5332 - Encoder-Garbedge_loss: 0.0138 - Encoder-Output_loss: 7.5194 - val_loss: 1.7760 - val_Encoder-Garbedge_loss: 0.0142 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4287 samples, validate on 226 samples\n",
      "Epoch 3061/3061\n",
      "4287/4287 [==============================] - 16s 4ms/step - loss: 9.4100 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 9.3966 - val_loss: 1.6808 - val_Encoder-Garbedge_loss: 0.0117 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 3027 samples, validate on 160 samples\n",
      "Epoch 3081/3081\n",
      "3027/3027 [==============================] - 11s 4ms/step - loss: 8.1566 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 8.1432 - val_loss: 1.8686 - val_Encoder-Garbedge_loss: 0.0142 - val_Encoder-Output_loss: 1.8544\n",
      "Train on 4067 samples, validate on 215 samples\n",
      "Epoch 3101/3101\n",
      "4067/4067 [==============================] - 15s 4ms/step - loss: 7.2152 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.2018 - val_loss: 1.6212 - val_Encoder-Garbedge_loss: 0.0133 - val_Encoder-Output_loss: 1.6080\n",
      "Train on 5628 samples, validate on 297 samples\n",
      "Epoch 3121/3121\n",
      "5628/5628 [==============================] - 21s 4ms/step - loss: 8.0047 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.9914 - val_loss: 1.6511 - val_Encoder-Garbedge_loss: 0.0129 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 4883 samples, validate on 257 samples\n",
      "Epoch 3141/3141\n",
      "4883/4883 [==============================] - 18s 4ms/step - loss: 7.7979 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.7844 - val_loss: 1.8334 - val_Encoder-Garbedge_loss: 0.0088 - val_Encoder-Output_loss: 1.8246\n",
      "Train on 4391 samples, validate on 232 samples\n",
      "Epoch 3161/3161\n",
      "4391/4391 [==============================] - 16s 4ms/step - loss: 5.6793 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 5.6659 - val_loss: 1.7429 - val_Encoder-Garbedge_loss: 0.0121 - val_Encoder-Output_loss: 1.7308\n",
      "Train on 5474 samples, validate on 289 samples\n",
      "Epoch 3181/3181\n",
      "5474/5474 [==============================] - 20s 4ms/step - loss: 7.2890 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.2758 - val_loss: 1.6843 - val_Encoder-Garbedge_loss: 0.0152 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 4681 samples, validate on 247 samples\n",
      "Epoch 3201/3201\n",
      "4681/4681 [==============================] - 17s 4ms/step - loss: 6.3250 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.3115 - val_loss: 1.8061 - val_Encoder-Garbedge_loss: 0.0134 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 4414 samples, validate on 233 samples\n",
      "Epoch 3221/3221\n",
      "4414/4414 [==============================] - 17s 4ms/step - loss: 7.4425 - Encoder-Garbedge_loss: 0.0129 - Encoder-Output_loss: 7.4296 - val_loss: 1.7505 - val_Encoder-Garbedge_loss: 0.0144 - val_Encoder-Output_loss: 1.7361\n",
      "Train on 6049 samples, validate on 319 samples\n",
      "Epoch 3241/3241\n",
      "6049/6049 [==============================] - 22s 4ms/step - loss: 8.3276 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 8.3145 - val_loss: 1.6661 - val_Encoder-Garbedge_loss: 0.0206 - val_Encoder-Output_loss: 1.6455\n",
      "Train on 4440 samples, validate on 234 samples\n",
      "Epoch 3261/3261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4440/4440 [==============================] - 16s 4ms/step - loss: 6.3916 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.3780 - val_loss: 1.7135 - val_Encoder-Garbedge_loss: 0.0134 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4445 samples, validate on 234 samples\n",
      "Epoch 3281/3281\n",
      "4445/4445 [==============================] - 16s 4ms/step - loss: 7.5736 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.5602 - val_loss: 1.8990 - val_Encoder-Garbedge_loss: 0.0137 - val_Encoder-Output_loss: 1.8853\n",
      "Train on 4634 samples, validate on 244 samples\n",
      "Epoch 3301/3301\n",
      "4634/4634 [==============================] - 17s 4ms/step - loss: 7.1929 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.1797 - val_loss: 1.6807 - val_Encoder-Garbedge_loss: 0.0114 - val_Encoder-Output_loss: 1.6693\n",
      "Train on 3845 samples, validate on 203 samples\n",
      "Epoch 3321/3321\n",
      "3845/3845 [==============================] - 14s 4ms/step - loss: 6.8273 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.8138 - val_loss: 1.7777 - val_Encoder-Garbedge_loss: 0.0159 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4028 samples, validate on 212 samples\n",
      "Epoch 3341/3341\n",
      "4028/4028 [==============================] - 15s 4ms/step - loss: 7.9950 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.9815 - val_loss: 1.6499 - val_Encoder-Garbedge_loss: 0.0118 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 1936 samples, validate on 102 samples\n",
      "Epoch 3361/3361\n",
      "1936/1936 [==============================] - 7s 4ms/step - loss: 10.8407 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 10.8273 - val_loss: 2.0209 - val_Encoder-Garbedge_loss: 0.0119 - val_Encoder-Output_loss: 2.0090\n",
      "Train on 4712 samples, validate on 249 samples\n",
      "Epoch 3381/3381\n",
      "4712/4712 [==============================] - 18s 4ms/step - loss: 6.9369 - Encoder-Garbedge_loss: 0.0129 - Encoder-Output_loss: 6.9240 - val_loss: 1.7888 - val_Encoder-Garbedge_loss: 0.0091 - val_Encoder-Output_loss: 1.7797\n",
      "Train on 4750 samples, validate on 251 samples\n",
      "Epoch 3401/3401\n",
      "4750/4750 [==============================] - 18s 4ms/step - loss: 7.9267 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 7.9131 - val_loss: 1.5884 - val_Encoder-Garbedge_loss: 0.0120 - val_Encoder-Output_loss: 1.5764\n",
      "Train on 5252 samples, validate on 277 samples\n",
      "Epoch 3421/3421\n",
      "5252/5252 [==============================] - 19s 4ms/step - loss: 6.1069 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 6.0938 - val_loss: 1.7726 - val_Encoder-Garbedge_loss: 0.0108 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4396 samples, validate on 232 samples\n",
      "Epoch 3441/3441\n",
      "4396/4396 [==============================] - 16s 4ms/step - loss: 6.8385 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.8252 - val_loss: 1.7715 - val_Encoder-Garbedge_loss: 0.0098 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4576 samples, validate on 241 samples\n",
      "Epoch 3461/3461\n",
      "4576/4576 [==============================] - 17s 4ms/step - loss: 6.9900 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.9764 - val_loss: 1.4628 - val_Encoder-Garbedge_loss: 0.0101 - val_Encoder-Output_loss: 1.4528\n",
      "Train on 5312 samples, validate on 280 samples\n",
      "Epoch 3481/3481\n",
      "5312/5312 [==============================] - 20s 4ms/step - loss: 6.1244 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 6.1108 - val_loss: 1.6486 - val_Encoder-Garbedge_loss: 0.0104 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 5139 samples, validate on 271 samples\n",
      "Epoch 3501/3501\n",
      "5139/5139 [==============================] - 19s 4ms/step - loss: 9.3916 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 9.3782 - val_loss: 1.8034 - val_Encoder-Garbedge_loss: 0.0107 - val_Encoder-Output_loss: 1.7927\n",
      "\n",
      "\n",
      "Train on 3935 samples, validate on 208 samples\n",
      "Epoch 3521/3521\n",
      "3935/3935 [==============================] - 15s 4ms/step - loss: 6.9725 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.9592 - val_loss: 1.8977 - val_Encoder-Garbedge_loss: 0.0122 - val_Encoder-Output_loss: 1.8855\n",
      "Train on 4031 samples, validate on 213 samples\n",
      "Epoch 3541/3541\n",
      "4031/4031 [==============================] - 15s 4ms/step - loss: 7.0364 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 7.0234 - val_loss: 1.6795 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 1.6690\n",
      "Train on 3729 samples, validate on 197 samples\n",
      "Epoch 3561/3561\n",
      "3729/3729 [==============================] - 14s 4ms/step - loss: 6.5707 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 6.5575 - val_loss: 1.7436 - val_Encoder-Garbedge_loss: 0.0114 - val_Encoder-Output_loss: 1.7321\n",
      "Train on 4362 samples, validate on 230 samples\n",
      "Epoch 3581/3581\n",
      "4362/4362 [==============================] - 16s 4ms/step - loss: 7.6130 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.5997 - val_loss: 1.8361 - val_Encoder-Garbedge_loss: 0.0125 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 3657 samples, validate on 193 samples\n",
      "Epoch 3601/3601\n",
      "3657/3657 [==============================] - 14s 4ms/step - loss: 8.8997 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 8.8865 - val_loss: 6.3667 - val_Encoder-Garbedge_loss: 0.0168 - val_Encoder-Output_loss: 6.3499\n",
      "Train on 4241 samples, validate on 224 samples\n",
      "Epoch 3621/3621\n",
      "4241/4241 [==============================] - 16s 4ms/step - loss: 6.7109 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.6977 - val_loss: 1.7167 - val_Encoder-Garbedge_loss: 0.0168 - val_Encoder-Output_loss: 1.6999\n",
      "Train on 2373 samples, validate on 125 samples\n",
      "Epoch 3641/3641\n",
      "2373/2373 [==============================] - 9s 4ms/step - loss: 5.4300 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 5.4167 - val_loss: 1.6523 - val_Encoder-Garbedge_loss: 0.0142 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 4390 samples, validate on 232 samples\n",
      "Epoch 3661/3661\n",
      "4390/4390 [==============================] - 16s 4ms/step - loss: 7.4776 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.4644 - val_loss: 1.6521 - val_Encoder-Garbedge_loss: 0.0139 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 4099 samples, validate on 216 samples\n",
      "Epoch 3681/3681\n",
      "4099/4099 [==============================] - 15s 4ms/step - loss: 7.4975 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.4842 - val_loss: 1.5876 - val_Encoder-Garbedge_loss: 0.0113 - val_Encoder-Output_loss: 1.5763\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 3701/3701\n",
      "4006/4006 [==============================] - 15s 4ms/step - loss: 9.2709 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 9.2579 - val_loss: 1.8055 - val_Encoder-Garbedge_loss: 0.0128 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 4707 samples, validate on 248 samples\n",
      "Epoch 3721/3721\n",
      "4707/4707 [==============================] - 18s 4ms/step - loss: 6.5502 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.5369 - val_loss: 1.8344 - val_Encoder-Garbedge_loss: 0.0108 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 2228 samples, validate on 118 samples\n",
      "Epoch 3741/3741\n",
      "2228/2228 [==============================] - 8s 4ms/step - loss: 9.5893 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 9.5760 - val_loss: 1.8951 - val_Encoder-Garbedge_loss: 0.0097 - val_Encoder-Output_loss: 1.8854\n",
      "Train on 4584 samples, validate on 242 samples\n",
      "Epoch 3761/3761\n",
      "4584/4584 [==============================] - 17s 4ms/step - loss: 6.4462 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 6.4331 - val_loss: 1.5832 - val_Encoder-Garbedge_loss: 0.0094 - val_Encoder-Output_loss: 1.5738\n",
      "Train on 4290 samples, validate on 226 samples\n",
      "Epoch 3781/3781\n",
      "4290/4290 [==============================] - 16s 4ms/step - loss: 7.1928 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.1794 - val_loss: 2.1166 - val_Encoder-Garbedge_loss: 0.0130 - val_Encoder-Output_loss: 2.1036\n",
      "Train on 3598 samples, validate on 190 samples\n",
      "Epoch 3801/3801\n",
      "3598/3598 [==============================] - 14s 4ms/step - loss: 6.5136 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.5002 - val_loss: 1.7089 - val_Encoder-Garbedge_loss: 0.0090 - val_Encoder-Output_loss: 1.6999\n",
      "Train on 4768 samples, validate on 251 samples\n",
      "Epoch 3821/3821\n",
      "4768/4768 [==============================] - 18s 4ms/step - loss: 7.1737 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.1605 - val_loss: 1.9262 - val_Encoder-Garbedge_loss: 0.0099 - val_Encoder-Output_loss: 1.9163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 3841/3841\n",
      "4006/4006 [==============================] - 15s 4ms/step - loss: 8.9912 - Encoder-Garbedge_loss: 0.0129 - Encoder-Output_loss: 8.9783 - val_loss: 2.6181 - val_Encoder-Garbedge_loss: 0.0107 - val_Encoder-Output_loss: 2.6074\n",
      "Train on 3825 samples, validate on 202 samples\n",
      "Epoch 3861/3861\n",
      "3825/3825 [==============================] - 14s 4ms/step - loss: 7.8090 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.7957 - val_loss: 1.7129 - val_Encoder-Garbedge_loss: 0.0129 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 5114 samples, validate on 270 samples\n",
      "Epoch 3881/3881\n",
      "5114/5114 [==============================] - 19s 4ms/step - loss: 7.6503 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.6369 - val_loss: 1.8635 - val_Encoder-Garbedge_loss: 0.0089 - val_Encoder-Output_loss: 1.8546\n",
      "Train on 4485 samples, validate on 237 samples\n",
      "Epoch 3901/3901\n",
      "4485/4485 [==============================] - 17s 4ms/step - loss: 7.0748 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.0613 - val_loss: 1.7136 - val_Encoder-Garbedge_loss: 0.0136 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 5190 samples, validate on 274 samples\n",
      "Epoch 3921/3921\n",
      "5190/5190 [==============================] - 19s 4ms/step - loss: 7.0784 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.0650 - val_loss: 1.7424 - val_Encoder-Garbedge_loss: 0.0115 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 3797 samples, validate on 200 samples\n",
      "Epoch 3941/3941\n",
      "3797/3797 [==============================] - 14s 4ms/step - loss: 5.9167 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 5.9030 - val_loss: 1.6300 - val_Encoder-Garbedge_loss: 0.0213 - val_Encoder-Output_loss: 1.6087\n",
      "Train on 4964 samples, validate on 262 samples\n",
      "Epoch 3961/3961\n",
      "4964/4964 [==============================] - 19s 4ms/step - loss: 5.4441 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 5.4305 - val_loss: 1.8659 - val_Encoder-Garbedge_loss: 0.0112 - val_Encoder-Output_loss: 1.8547\n",
      "Train on 5469 samples, validate on 288 samples\n",
      "Epoch 3981/3981\n",
      "5469/5469 [==============================] - 21s 4ms/step - loss: 7.0130 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.9997 - val_loss: 1.8074 - val_Encoder-Garbedge_loss: 0.0147 - val_Encoder-Output_loss: 1.7927\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "**********************************\n",
      "\n",
      "Train on 4323 samples, validate on 228 samples\n",
      "Epoch 4001/4001\n",
      "4323/4323 [==============================] - 16s 4ms/step - loss: 6.7529 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.7394 - val_loss: 1.7731 - val_Encoder-Garbedge_loss: 0.0113 - val_Encoder-Output_loss: 1.7618\n",
      "\n",
      "\n",
      "Train on 2870 samples, validate on 152 samples\n",
      "Epoch 4021/4021\n",
      "2870/2870 [==============================] - 11s 4ms/step - loss: 10.5217 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 10.5088 - val_loss: 2.3345 - val_Encoder-Garbedge_loss: 0.0152 - val_Encoder-Output_loss: 2.3193\n",
      "Train on 5088 samples, validate on 268 samples\n",
      "Epoch 4041/4041\n",
      "5088/5088 [==============================] - 19s 4ms/step - loss: 7.5296 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 7.5161 - val_loss: 1.8048 - val_Encoder-Garbedge_loss: 0.0121 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 4287 samples, validate on 226 samples\n",
      "Epoch 4061/4061\n",
      "4287/4287 [==============================] - 16s 4ms/step - loss: 9.3641 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 9.3506 - val_loss: 1.6796 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 3027 samples, validate on 160 samples\n",
      "Epoch 4081/4081\n",
      "3027/3027 [==============================] - 12s 4ms/step - loss: 8.1630 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 8.1499 - val_loss: 1.9288 - val_Encoder-Garbedge_loss: 0.0125 - val_Encoder-Output_loss: 1.9163\n",
      "Train on 4067 samples, validate on 215 samples\n",
      "Epoch 4101/4101\n",
      "4067/4067 [==============================] - 15s 4ms/step - loss: 7.1094 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.0962 - val_loss: 1.5862 - val_Encoder-Garbedge_loss: 0.0099 - val_Encoder-Output_loss: 1.5763\n",
      "Train on 5628 samples, validate on 297 samples\n",
      "Epoch 4121/4121\n",
      "5628/5628 [==============================] - 21s 4ms/step - loss: 8.1021 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 8.0887 - val_loss: 2.6022 - val_Encoder-Garbedge_loss: 0.0104 - val_Encoder-Output_loss: 2.5918\n",
      "Train on 4883 samples, validate on 257 samples\n",
      "Epoch 4141/4141\n",
      "4883/4883 [==============================] - 18s 4ms/step - loss: 7.7016 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.6882 - val_loss: 1.7737 - val_Encoder-Garbedge_loss: 0.0119 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4391 samples, validate on 232 samples\n",
      "Epoch 4161/4161\n",
      "4391/4391 [==============================] - 16s 4ms/step - loss: 5.6553 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 5.6418 - val_loss: 1.6190 - val_Encoder-Garbedge_loss: 0.0110 - val_Encoder-Output_loss: 1.6079\n",
      "Train on 5474 samples, validate on 289 samples\n",
      "Epoch 4181/4181\n",
      "5474/5474 [==============================] - 20s 4ms/step - loss: 7.1586 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.1454 - val_loss: 1.6487 - val_Encoder-Garbedge_loss: 0.0106 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 4681 samples, validate on 247 samples\n",
      "Epoch 4201/4201\n",
      "4681/4681 [==============================] - 17s 4ms/step - loss: 6.3754 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.3620 - val_loss: 1.7793 - val_Encoder-Garbedge_loss: 0.0171 - val_Encoder-Output_loss: 1.7622\n",
      "Train on 4414 samples, validate on 233 samples\n",
      "Epoch 4221/4221\n",
      "4414/4414 [==============================] - 16s 4ms/step - loss: 7.5761 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.5628 - val_loss: 1.7431 - val_Encoder-Garbedge_loss: 0.0122 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 6049 samples, validate on 319 samples\n",
      "Epoch 4241/4241\n",
      "6049/6049 [==============================] - 23s 4ms/step - loss: 8.4008 - Encoder-Garbedge_loss: 0.0129 - Encoder-Output_loss: 8.3879 - val_loss: 1.6932 - val_Encoder-Garbedge_loss: 0.0207 - val_Encoder-Output_loss: 1.6724\n",
      "Train on 4440 samples, validate on 234 samples\n",
      "Epoch 4261/4261\n",
      "4440/4440 [==============================] - 16s 4ms/step - loss: 6.3140 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.3005 - val_loss: 1.6807 - val_Encoder-Garbedge_loss: 0.0104 - val_Encoder-Output_loss: 1.6703\n",
      "Train on 4445 samples, validate on 234 samples\n",
      "Epoch 4281/4281\n",
      "4445/4445 [==============================] - 17s 4ms/step - loss: 7.5010 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 7.4873 - val_loss: 1.7768 - val_Encoder-Garbedge_loss: 0.0150 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4634 samples, validate on 244 samples\n",
      "Epoch 4301/4301\n",
      "4634/4634 [==============================] - 17s 4ms/step - loss: 7.1913 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.1779 - val_loss: 1.7124 - val_Encoder-Garbedge_loss: 0.0124 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 3845 samples, validate on 203 samples\n",
      "Epoch 4321/4321\n",
      "3845/3845 [==============================] - 14s 4ms/step - loss: 6.8312 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.8177 - val_loss: 1.7929 - val_Encoder-Garbedge_loss: 0.0135 - val_Encoder-Output_loss: 1.7795\n",
      "Train on 4028 samples, validate on 212 samples\n",
      "Epoch 4341/4341\n",
      "4028/4028 [==============================] - 15s 4ms/step - loss: 8.0013 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 7.9877 - val_loss: 1.6522 - val_Encoder-Garbedge_loss: 0.0141 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 1936 samples, validate on 102 samples\n",
      "Epoch 4361/4361\n",
      "1936/1936 [==============================] - 7s 4ms/step - loss: 10.8679 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 10.8543 - val_loss: 2.0819 - val_Encoder-Garbedge_loss: 0.0111 - val_Encoder-Output_loss: 2.0708\n",
      "Train on 4712 samples, validate on 249 samples\n",
      "Epoch 4381/4381\n",
      "4712/4712 [==============================] - 18s 4ms/step - loss: 6.9774 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 6.9643 - val_loss: 1.7403 - val_Encoder-Garbedge_loss: 0.0095 - val_Encoder-Output_loss: 1.7308\n",
      "Train on 4750 samples, validate on 251 samples\n",
      "Epoch 4401/4401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750/4750 [==============================] - 18s 4ms/step - loss: 7.9857 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.9724 - val_loss: 1.7756 - val_Encoder-Garbedge_loss: 0.0139 - val_Encoder-Output_loss: 1.7617\n",
      "Train on 5252 samples, validate on 277 samples\n",
      "Epoch 4421/4421\n",
      "5252/5252 [==============================] - 20s 4ms/step - loss: 6.1296 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.1161 - val_loss: 1.6542 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 1.6436\n",
      "Train on 4396 samples, validate on 232 samples\n",
      "Epoch 4441/4441\n",
      "4396/4396 [==============================] - 17s 4ms/step - loss: 6.7862 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.7728 - val_loss: 1.6505 - val_Encoder-Garbedge_loss: 0.0123 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 4576 samples, validate on 241 samples\n",
      "Epoch 4461/4461\n",
      "4576/4576 [==============================] - 17s 4ms/step - loss: 7.0406 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 7.0269 - val_loss: 1.6178 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 1.6073\n",
      "Train on 5312 samples, validate on 280 samples\n",
      "Epoch 4481/4481\n",
      "5312/5312 [==============================] - 20s 4ms/step - loss: 6.0533 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.0400 - val_loss: 1.5865 - val_Encoder-Garbedge_loss: 0.0102 - val_Encoder-Output_loss: 1.5763\n",
      "Train on 5139 samples, validate on 271 samples\n",
      "Epoch 4501/4501\n",
      "5139/5139 [==============================] - 19s 4ms/step - loss: 9.3820 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 9.3685 - val_loss: 1.8981 - val_Encoder-Garbedge_loss: 0.0127 - val_Encoder-Output_loss: 1.8854\n",
      "\n",
      "\n",
      "Train on 3935 samples, validate on 208 samples\n",
      "Epoch 4521/4521\n",
      "3935/3935 [==============================] - 15s 4ms/step - loss: 6.8625 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 6.8490 - val_loss: 1.7753 - val_Encoder-Garbedge_loss: 0.0133 - val_Encoder-Output_loss: 1.7621\n",
      "Train on 4031 samples, validate on 213 samples\n",
      "Epoch 4541/4541\n",
      "4031/4031 [==============================] - 15s 4ms/step - loss: 7.1200 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.1069 - val_loss: 1.7120 - val_Encoder-Garbedge_loss: 0.0121 - val_Encoder-Output_loss: 1.6999\n",
      "Train on 3729 samples, validate on 197 samples\n",
      "Epoch 4561/4561\n",
      "3729/3729 [==============================] - 14s 4ms/step - loss: 6.5850 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.5716 - val_loss: 1.7153 - val_Encoder-Garbedge_loss: 0.0154 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4362 samples, validate on 230 samples\n",
      "Epoch 4581/4581\n",
      "4362/4362 [==============================] - 16s 4ms/step - loss: 7.5083 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.4948 - val_loss: 1.7444 - val_Encoder-Garbedge_loss: 0.0135 - val_Encoder-Output_loss: 1.7308\n",
      "Train on 3657 samples, validate on 193 samples\n",
      "Epoch 4601/4601\n",
      "3657/3657 [==============================] - 14s 4ms/step - loss: 9.0204 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 9.0071 - val_loss: 1.8740 - val_Encoder-Garbedge_loss: 0.0196 - val_Encoder-Output_loss: 1.8544\n",
      "Train on 4241 samples, validate on 224 samples\n",
      "Epoch 4621/4621\n",
      "4241/4241 [==============================] - 16s 4ms/step - loss: 6.8100 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.7967 - val_loss: 1.9344 - val_Encoder-Garbedge_loss: 0.0132 - val_Encoder-Output_loss: 1.9212\n",
      "Train on 2373 samples, validate on 125 samples\n",
      "Epoch 4641/4641\n",
      "2373/2373 [==============================] - 9s 4ms/step - loss: 5.4548 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 5.4415 - val_loss: 1.7144 - val_Encoder-Garbedge_loss: 0.0144 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4390 samples, validate on 232 samples\n",
      "Epoch 4661/4661\n",
      "4390/4390 [==============================] - 16s 4ms/step - loss: 7.6799 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.6666 - val_loss: 1.8370 - val_Encoder-Garbedge_loss: 0.0142 - val_Encoder-Output_loss: 1.8228\n",
      "Train on 4099 samples, validate on 216 samples\n",
      "Epoch 4681/4681\n",
      "4099/4099 [==============================] - 15s 4ms/step - loss: 7.6246 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.6113 - val_loss: 1.7429 - val_Encoder-Garbedge_loss: 0.0120 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 4701/4701\n",
      "4006/4006 [==============================] - 15s 4ms/step - loss: 9.1970 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 9.1837 - val_loss: 1.8170 - val_Encoder-Garbedge_loss: 0.0119 - val_Encoder-Output_loss: 1.8051\n",
      "Train on 4707 samples, validate on 248 samples\n",
      "Epoch 4721/4721\n",
      "4707/4707 [==============================] - 18s 4ms/step - loss: 6.5313 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 6.5176 - val_loss: 1.8073 - val_Encoder-Garbedge_loss: 0.0142 - val_Encoder-Output_loss: 1.7932\n",
      "Train on 2228 samples, validate on 118 samples\n",
      "Epoch 4741/4741\n",
      "2228/2228 [==============================] - 9s 4ms/step - loss: 9.6637 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 9.6501 - val_loss: 1.7720 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 1.7615\n",
      "Train on 4584 samples, validate on 242 samples\n",
      "Epoch 4761/4761\n",
      "4584/4584 [==============================] - 17s 4ms/step - loss: 6.5532 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.5397 - val_loss: 1.6490 - val_Encoder-Garbedge_loss: 0.0107 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 4290 samples, validate on 226 samples\n",
      "Epoch 4781/4781\n",
      "4290/4290 [==============================] - 16s 4ms/step - loss: 6.9378 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.9246 - val_loss: 1.8658 - val_Encoder-Garbedge_loss: 0.0112 - val_Encoder-Output_loss: 1.8545\n",
      "Train on 3598 samples, validate on 190 samples\n",
      "Epoch 4801/4801\n",
      "3598/3598 [==============================] - 13s 4ms/step - loss: 6.6077 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.5945 - val_loss: 1.8340 - val_Encoder-Garbedge_loss: 0.0106 - val_Encoder-Output_loss: 1.8235\n",
      "Train on 4768 samples, validate on 251 samples\n",
      "Epoch 4821/4821\n",
      "4768/4768 [==============================] - 17s 4ms/step - loss: 7.2091 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.1959 - val_loss: 1.9588 - val_Encoder-Garbedge_loss: 0.0115 - val_Encoder-Output_loss: 1.9473\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 4841/4841\n",
      "4006/4006 [==============================] - 15s 4ms/step - loss: 8.9570 - Encoder-Garbedge_loss: 0.0129 - Encoder-Output_loss: 8.9441 - val_loss: 1.5580 - val_Encoder-Garbedge_loss: 0.0126 - val_Encoder-Output_loss: 1.5454\n",
      "Train on 3825 samples, validate on 202 samples\n",
      "Epoch 4861/4861\n",
      "3825/3825 [==============================] - 15s 4ms/step - loss: 7.6342 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.6209 - val_loss: 1.6212 - val_Encoder-Garbedge_loss: 0.0139 - val_Encoder-Output_loss: 1.6073\n",
      "Train on 5114 samples, validate on 270 samples\n",
      "Epoch 4881/4881\n",
      "5114/5114 [==============================] - 19s 4ms/step - loss: 7.7302 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.7170 - val_loss: 1.8670 - val_Encoder-Garbedge_loss: 0.0125 - val_Encoder-Output_loss: 1.8545\n",
      "Train on 4485 samples, validate on 237 samples\n",
      "Epoch 4901/4901\n",
      "4485/4485 [==============================] - 18s 4ms/step - loss: 7.0023 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.9890 - val_loss: 1.7318 - val_Encoder-Garbedge_loss: 0.0135 - val_Encoder-Output_loss: 1.7183\n",
      "Train on 5190 samples, validate on 274 samples\n",
      "Epoch 4921/4921\n",
      "5190/5190 [==============================] - 21s 4ms/step - loss: 7.2366 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.2235 - val_loss: 1.8363 - val_Encoder-Garbedge_loss: 0.0130 - val_Encoder-Output_loss: 1.8234\n",
      "Train on 3797 samples, validate on 200 samples\n",
      "Epoch 4941/4941\n",
      "3797/3797 [==============================] - 15s 4ms/step - loss: 5.9563 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 5.9429 - val_loss: 1.7428 - val_Encoder-Garbedge_loss: 0.0119 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 4964 samples, validate on 262 samples\n",
      "Epoch 4961/4961\n",
      "4964/4964 [==============================] - 18s 4ms/step - loss: 5.4593 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 5.4457 - val_loss: 1.8964 - val_Encoder-Garbedge_loss: 0.0110 - val_Encoder-Output_loss: 1.8854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5469 samples, validate on 288 samples\n",
      "Epoch 4981/4981\n",
      "5469/5469 [==============================] - 22s 4ms/step - loss: 7.0962 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.0828 - val_loss: 1.7447 - val_Encoder-Garbedge_loss: 0.0156 - val_Encoder-Output_loss: 1.7291\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "**********************************\n",
      "\n",
      "Train on 4323 samples, validate on 228 samples\n",
      "Epoch 5001/5001\n",
      "4323/4323 [==============================] - 17s 4ms/step - loss: 6.7808 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.7675 - val_loss: 1.7417 - val_Encoder-Garbedge_loss: 0.0108 - val_Encoder-Output_loss: 1.7309\n",
      "\n",
      "\n",
      "Train on 2870 samples, validate on 152 samples\n",
      "Epoch 5021/5021\n",
      "2870/2870 [==============================] - 11s 4ms/step - loss: 10.3764 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 10.3628 - val_loss: 1.8070 - val_Encoder-Garbedge_loss: 0.0143 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 5088 samples, validate on 268 samples\n",
      "Epoch 5041/5041\n",
      "5088/5088 [==============================] - 19s 4ms/step - loss: 7.5116 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.4982 - val_loss: 1.7424 - val_Encoder-Garbedge_loss: 0.0115 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 4287 samples, validate on 226 samples\n",
      "Epoch 5061/5061\n",
      "4287/4287 [==============================] - 16s 4ms/step - loss: 9.4054 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 9.3919 - val_loss: 1.6509 - val_Encoder-Garbedge_loss: 0.0128 - val_Encoder-Output_loss: 1.6381\n",
      "Train on 3027 samples, validate on 160 samples\n",
      "Epoch 5081/5081\n",
      "3027/3027 [==============================] - 11s 4ms/step - loss: 8.1360 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 8.1229 - val_loss: 1.8652 - val_Encoder-Garbedge_loss: 0.0107 - val_Encoder-Output_loss: 1.8545\n",
      "Train on 4067 samples, validate on 215 samples\n",
      "Epoch 5101/5101\n",
      "4067/4067 [==============================] - 15s 4ms/step - loss: 7.2222 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.2090 - val_loss: 1.7124 - val_Encoder-Garbedge_loss: 0.0124 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 5628 samples, validate on 297 samples\n",
      "Epoch 5121/5121\n",
      "5628/5628 [==============================] - 20s 4ms/step - loss: 8.1568 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 8.1432 - val_loss: 1.6787 - val_Encoder-Garbedge_loss: 0.0097 - val_Encoder-Output_loss: 1.6690\n",
      "Train on 4883 samples, validate on 257 samples\n",
      "Epoch 5141/5141\n",
      "4883/4883 [==============================] - 19s 4ms/step - loss: 7.6325 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 7.6190 - val_loss: 1.6195 - val_Encoder-Garbedge_loss: 0.0122 - val_Encoder-Output_loss: 1.6073\n",
      "Train on 4391 samples, validate on 232 samples\n",
      "Epoch 5161/5161\n",
      "4391/4391 [==============================] - 17s 4ms/step - loss: 5.7578 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 5.7443 - val_loss: 1.6807 - val_Encoder-Garbedge_loss: 0.0118 - val_Encoder-Output_loss: 1.6689\n",
      "Train on 5474 samples, validate on 289 samples\n",
      "Epoch 5181/5181\n",
      "5474/5474 [==============================] - 20s 4ms/step - loss: 7.0842 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.0710 - val_loss: 1.5282 - val_Encoder-Garbedge_loss: 0.0137 - val_Encoder-Output_loss: 1.5145\n",
      "Train on 4681 samples, validate on 247 samples\n",
      "Epoch 5201/5201\n",
      "4681/4681 [==============================] - 17s 4ms/step - loss: 6.2664 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.2529 - val_loss: 1.7778 - val_Encoder-Garbedge_loss: 0.0160 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4414 samples, validate on 233 samples\n",
      "Epoch 5221/5221\n",
      "4414/4414 [==============================] - 17s 4ms/step - loss: 7.5775 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.5643 - val_loss: 1.7127 - val_Encoder-Garbedge_loss: 0.0127 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 6049 samples, validate on 319 samples\n",
      "Epoch 5241/5241\n",
      "6049/6049 [==============================] - 22s 4ms/step - loss: 8.3359 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 8.3227 - val_loss: 1.6228 - val_Encoder-Garbedge_loss: 0.0154 - val_Encoder-Output_loss: 1.6074\n",
      "Train on 4440 samples, validate on 234 samples\n",
      "Epoch 5261/5261\n",
      "4440/4440 [==============================] - 16s 4ms/step - loss: 6.2935 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 6.2804 - val_loss: 1.7121 - val_Encoder-Garbedge_loss: 0.0121 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4445 samples, validate on 234 samples\n",
      "Epoch 5281/5281\n",
      "4445/4445 [==============================] - 16s 4ms/step - loss: 7.3184 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 7.3048 - val_loss: 1.7112 - val_Encoder-Garbedge_loss: 0.0129 - val_Encoder-Output_loss: 1.6983\n",
      "Train on 4634 samples, validate on 244 samples\n",
      "Epoch 5301/5301\n",
      "4634/4634 [==============================] - 17s 4ms/step - loss: 7.2331 - Encoder-Garbedge_loss: 0.0138 - Encoder-Output_loss: 7.2194 - val_loss: 1.8049 - val_Encoder-Garbedge_loss: 0.0131 - val_Encoder-Output_loss: 1.7918\n",
      "Train on 3845 samples, validate on 203 samples\n",
      "Epoch 5321/5321\n",
      "3845/3845 [==============================] - 15s 4ms/step - loss: 6.8016 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.7884 - val_loss: 1.7134 - val_Encoder-Garbedge_loss: 0.0134 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4028 samples, validate on 212 samples\n",
      "Epoch 5341/5341\n",
      "4028/4028 [==============================] - 16s 4ms/step - loss: 8.1192 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 8.1056 - val_loss: 1.7716 - val_Encoder-Garbedge_loss: 0.0121 - val_Encoder-Output_loss: 1.7595\n",
      "Train on 1936 samples, validate on 102 samples\n",
      "Epoch 5361/5361\n",
      "1936/1936 [==============================] - 8s 4ms/step - loss: 10.7530 - Encoder-Garbedge_loss: 0.0139 - Encoder-Output_loss: 10.7391 - val_loss: 1.9599 - val_Encoder-Garbedge_loss: 0.0126 - val_Encoder-Output_loss: 1.9473\n",
      "Train on 4712 samples, validate on 249 samples\n",
      "Epoch 5381/5381\n",
      "4712/4712 [==============================] - 19s 4ms/step - loss: 6.9219 - Encoder-Garbedge_loss: 0.0129 - Encoder-Output_loss: 6.9090 - val_loss: 1.6482 - val_Encoder-Garbedge_loss: 0.0098 - val_Encoder-Output_loss: 1.6384\n",
      "Train on 4750 samples, validate on 251 samples\n",
      "Epoch 5401/5401\n",
      "4750/4750 [==============================] - 19s 4ms/step - loss: 7.9413 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.9279 - val_loss: 1.6175 - val_Encoder-Garbedge_loss: 0.0103 - val_Encoder-Output_loss: 1.6073\n",
      "Train on 5252 samples, validate on 277 samples\n",
      "Epoch 5421/5421\n",
      "5252/5252 [==============================] - 21s 4ms/step - loss: 6.1537 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.1406 - val_loss: 1.7134 - val_Encoder-Garbedge_loss: 0.0134 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4396 samples, validate on 232 samples\n",
      "Epoch 5441/5441\n",
      "4396/4396 [==============================] - 17s 4ms/step - loss: 6.8916 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.8781 - val_loss: 1.8049 - val_Encoder-Garbedge_loss: 0.0122 - val_Encoder-Output_loss: 1.7926\n",
      "Train on 4576 samples, validate on 241 samples\n",
      "Epoch 5461/5461\n",
      "4576/4576 [==============================] - 18s 4ms/step - loss: 6.9652 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.9518 - val_loss: 1.4353 - val_Encoder-Garbedge_loss: 0.0135 - val_Encoder-Output_loss: 1.4218\n",
      "Train on 5312 samples, validate on 280 samples\n",
      "Epoch 5481/5481\n",
      "5312/5312 [==============================] - 21s 4ms/step - loss: 6.0087 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 5.9954 - val_loss: 1.4937 - val_Encoder-Garbedge_loss: 0.0101 - val_Encoder-Output_loss: 1.4836\n",
      "Train on 5139 samples, validate on 271 samples\n",
      "Epoch 5501/5501\n",
      "5139/5139 [==============================] - 20s 4ms/step - loss: 9.2273 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 9.2140 - val_loss: 1.9865 - val_Encoder-Garbedge_loss: 0.0127 - val_Encoder-Output_loss: 1.9738\n",
      "\n",
      "\n",
      "Train on 3935 samples, validate on 208 samples\n",
      "Epoch 5521/5521\n",
      "3935/3935 [==============================] - 16s 4ms/step - loss: 6.9421 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.9289 - val_loss: 1.8330 - val_Encoder-Garbedge_loss: 0.0093 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 4031 samples, validate on 213 samples\n",
      "Epoch 5541/5541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4031/4031 [==============================] - 15s 4ms/step - loss: 7.0925 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.0794 - val_loss: 1.7424 - val_Encoder-Garbedge_loss: 0.0115 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 3729 samples, validate on 197 samples\n",
      "Epoch 5561/5561\n",
      "3729/3729 [==============================] - 15s 4ms/step - loss: 6.5720 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.5588 - val_loss: 2.5671 - val_Encoder-Garbedge_loss: 0.0158 - val_Encoder-Output_loss: 2.5513\n",
      "Train on 4362 samples, validate on 230 samples\n",
      "Epoch 5581/5581\n",
      "4362/4362 [==============================] - 17s 4ms/step - loss: 7.5504 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.5370 - val_loss: 1.7722 - val_Encoder-Garbedge_loss: 0.0104 - val_Encoder-Output_loss: 1.7617\n",
      "Train on 3657 samples, validate on 193 samples\n",
      "Epoch 5601/5601\n",
      "3657/3657 [==============================] - 14s 4ms/step - loss: 9.0234 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 9.0099 - val_loss: 1.8700 - val_Encoder-Garbedge_loss: 0.0155 - val_Encoder-Output_loss: 1.8545\n",
      "Train on 4241 samples, validate on 224 samples\n",
      "Epoch 5621/5621\n",
      "4241/4241 [==============================] - 17s 4ms/step - loss: 6.7404 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.7271 - val_loss: 1.6250 - val_Encoder-Garbedge_loss: 0.0170 - val_Encoder-Output_loss: 1.6080\n",
      "Train on 2373 samples, validate on 125 samples\n",
      "Epoch 5641/5641\n",
      "2373/2373 [==============================] - 9s 4ms/step - loss: 5.4431 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 5.4298 - val_loss: 1.7759 - val_Encoder-Garbedge_loss: 0.0141 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4390 samples, validate on 232 samples\n",
      "Epoch 5661/5661\n",
      "4390/4390 [==============================] - 18s 4ms/step - loss: 7.6317 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 7.6180 - val_loss: 1.7428 - val_Encoder-Garbedge_loss: 0.0121 - val_Encoder-Output_loss: 1.7307\n",
      "Train on 4099 samples, validate on 216 samples\n",
      "Epoch 5681/5681\n",
      "4099/4099 [==============================] - 16s 4ms/step - loss: 7.6001 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.5867 - val_loss: 1.7118 - val_Encoder-Garbedge_loss: 0.0120 - val_Encoder-Output_loss: 1.6998\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 5701/5701\n",
      "4006/4006 [==============================] - 15s 4ms/step - loss: 9.1699 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 9.1564 - val_loss: 1.7138 - val_Encoder-Garbedge_loss: 0.0138 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4707 samples, validate on 248 samples\n",
      "Epoch 5721/5721\n",
      "4707/4707 [==============================] - 17s 4ms/step - loss: 6.5317 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.5182 - val_loss: 1.7718 - val_Encoder-Garbedge_loss: 0.0104 - val_Encoder-Output_loss: 1.7614\n",
      "Train on 2228 samples, validate on 118 samples\n",
      "Epoch 5741/5741\n",
      "2228/2228 [==============================] - 8s 4ms/step - loss: 9.5267 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 9.5133 - val_loss: 1.7730 - val_Encoder-Garbedge_loss: 0.0127 - val_Encoder-Output_loss: 1.7603\n",
      "Train on 4584 samples, validate on 242 samples\n",
      "Epoch 5761/5761\n",
      "4584/4584 [==============================] - 17s 4ms/step - loss: 6.5397 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.5264 - val_loss: 1.6495 - val_Encoder-Garbedge_loss: 0.0113 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 4290 samples, validate on 226 samples\n",
      "Epoch 5781/5781\n",
      "4290/4290 [==============================] - 16s 4ms/step - loss: 7.1596 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.1461 - val_loss: 2.1719 - val_Encoder-Garbedge_loss: 0.0125 - val_Encoder-Output_loss: 2.1593\n",
      "Train on 3598 samples, validate on 190 samples\n",
      "Epoch 5801/5801\n",
      "3598/3598 [==============================] - 13s 4ms/step - loss: 6.5901 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.5766 - val_loss: 1.8335 - val_Encoder-Garbedge_loss: 0.0099 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 4768 samples, validate on 251 samples\n",
      "Epoch 5821/5821\n",
      "4768/4768 [==============================] - 17s 4ms/step - loss: 7.2101 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.1968 - val_loss: 1.9879 - val_Encoder-Garbedge_loss: 0.0098 - val_Encoder-Output_loss: 1.9782\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 5841/5841\n",
      "4006/4006 [==============================] - 15s 4ms/step - loss: 8.9929 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 8.9798 - val_loss: 1.6253 - val_Encoder-Garbedge_loss: 0.0129 - val_Encoder-Output_loss: 1.6124\n",
      "Train on 3825 samples, validate on 202 samples\n",
      "Epoch 5861/5861\n",
      "3825/3825 [==============================] - 14s 4ms/step - loss: 7.6306 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.6175 - val_loss: 1.5914 - val_Encoder-Garbedge_loss: 0.0151 - val_Encoder-Output_loss: 1.5763\n",
      "Train on 5114 samples, validate on 270 samples\n",
      "Epoch 5881/5881\n",
      "5114/5114 [==============================] - 19s 4ms/step - loss: 7.6748 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.6616 - val_loss: 1.9305 - val_Encoder-Garbedge_loss: 0.0128 - val_Encoder-Output_loss: 1.9177\n",
      "Train on 4485 samples, validate on 237 samples\n",
      "Epoch 5901/5901\n",
      "4485/4485 [==============================] - 16s 4ms/step - loss: 7.0076 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.9941 - val_loss: 1.7128 - val_Encoder-Garbedge_loss: 0.0129 - val_Encoder-Output_loss: 1.6999\n",
      "Train on 5190 samples, validate on 274 samples\n",
      "Epoch 5921/5921\n",
      "5190/5190 [==============================] - 19s 4ms/step - loss: 7.0952 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.0818 - val_loss: 6.6034 - val_Encoder-Garbedge_loss: 0.0140 - val_Encoder-Output_loss: 6.5894\n",
      "Train on 3797 samples, validate on 200 samples\n",
      "Epoch 5941/5941\n",
      "3797/3797 [==============================] - 14s 4ms/step - loss: 5.8609 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 5.8476 - val_loss: 1.6548 - val_Encoder-Garbedge_loss: 0.0166 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 4964 samples, validate on 262 samples\n",
      "Epoch 5961/5961\n",
      "4964/4964 [==============================] - 18s 4ms/step - loss: 5.5182 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 5.5045 - val_loss: 1.9282 - val_Encoder-Garbedge_loss: 0.0118 - val_Encoder-Output_loss: 1.9163\n",
      "Train on 5469 samples, validate on 288 samples\n",
      "Epoch 5981/5981\n",
      "5469/5469 [==============================] - 20s 4ms/step - loss: 7.0433 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.0302 - val_loss: 1.6516 - val_Encoder-Garbedge_loss: 0.0131 - val_Encoder-Output_loss: 1.6385\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "**********************************\n",
      "\n",
      "Train on 4323 samples, validate on 228 samples\n",
      "Epoch 6001/6001\n",
      "4323/4323 [==============================] - 16s 4ms/step - loss: 6.7084 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.6951 - val_loss: 1.7116 - val_Encoder-Garbedge_loss: 0.0117 - val_Encoder-Output_loss: 1.7000\n",
      "\n",
      "\n",
      "Train on 2870 samples, validate on 152 samples\n",
      "Epoch 6021/6021\n",
      "2870/2870 [==============================] - 11s 4ms/step - loss: 10.4354 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 10.4221 - val_loss: 2.1378 - val_Encoder-Garbedge_loss: 0.0130 - val_Encoder-Output_loss: 2.1248\n",
      "Train on 5088 samples, validate on 268 samples\n",
      "Epoch 6041/6041\n",
      "5088/5088 [==============================] - 19s 4ms/step - loss: 7.5304 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.5171 - val_loss: 1.7436 - val_Encoder-Garbedge_loss: 0.0127 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 4287 samples, validate on 226 samples\n",
      "Epoch 6061/6061\n",
      "4287/4287 [==============================] - 16s 4ms/step - loss: 9.3527 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 9.3391 - val_loss: 1.6202 - val_Encoder-Garbedge_loss: 0.0129 - val_Encoder-Output_loss: 1.6073\n",
      "Train on 3027 samples, validate on 160 samples\n",
      "Epoch 6081/6081\n",
      "3027/3027 [==============================] - 11s 4ms/step - loss: 8.1463 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 8.1331 - val_loss: 1.8026 - val_Encoder-Garbedge_loss: 0.0113 - val_Encoder-Output_loss: 1.7914\n",
      "Train on 4067 samples, validate on 215 samples\n",
      "Epoch 6101/6101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4067/4067 [==============================] - 15s 4ms/step - loss: 7.1514 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.1380 - val_loss: 1.5905 - val_Encoder-Garbedge_loss: 0.0141 - val_Encoder-Output_loss: 1.5763\n",
      "Train on 5628 samples, validate on 297 samples\n",
      "Epoch 6121/6121\n",
      "5628/5628 [==============================] - 21s 4ms/step - loss: 7.9586 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.9451 - val_loss: 1.5893 - val_Encoder-Garbedge_loss: 0.0130 - val_Encoder-Output_loss: 1.5764\n",
      "Train on 4883 samples, validate on 257 samples\n",
      "Epoch 6141/6141\n",
      "4883/4883 [==============================] - 18s 4ms/step - loss: 7.6500 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.6367 - val_loss: 1.7096 - val_Encoder-Garbedge_loss: 0.0096 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4391 samples, validate on 232 samples\n",
      "Epoch 6161/6161\n",
      "4391/4391 [==============================] - 16s 4ms/step - loss: 5.6428 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 5.6295 - val_loss: 2.0941 - val_Encoder-Garbedge_loss: 0.0116 - val_Encoder-Output_loss: 2.0825\n",
      "Train on 5474 samples, validate on 289 samples\n",
      "Epoch 6181/6181\n",
      "5474/5474 [==============================] - 19s 4ms/step - loss: 7.1341 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.1210 - val_loss: 1.5274 - val_Encoder-Garbedge_loss: 0.0129 - val_Encoder-Output_loss: 1.5145\n",
      "Train on 4681 samples, validate on 247 samples\n",
      "Epoch 6201/6201\n",
      "4681/4681 [==============================] - 17s 4ms/step - loss: 6.3087 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.2953 - val_loss: 1.8103 - val_Encoder-Garbedge_loss: 0.0175 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 4414 samples, validate on 233 samples\n",
      "Epoch 6221/6221\n",
      "4414/4414 [==============================] - 16s 4ms/step - loss: 7.4707 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 7.4570 - val_loss: 1.7203 - val_Encoder-Garbedge_loss: 0.0112 - val_Encoder-Output_loss: 1.7091\n",
      "Train on 6049 samples, validate on 319 samples\n",
      "Epoch 6241/6241\n",
      "6049/6049 [==============================] - 21s 4ms/step - loss: 8.3549 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 8.3417 - val_loss: 1.6560 - val_Encoder-Garbedge_loss: 0.0178 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 4440 samples, validate on 234 samples\n",
      "Epoch 6261/6261\n",
      "4440/4440 [==============================] - 16s 4ms/step - loss: 6.2826 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.2693 - val_loss: 1.5567 - val_Encoder-Garbedge_loss: 0.0109 - val_Encoder-Output_loss: 1.5459\n",
      "Train on 4445 samples, validate on 234 samples\n",
      "Epoch 6281/6281\n",
      "4445/4445 [==============================] - 16s 4ms/step - loss: 7.5606 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.5471 - val_loss: 1.9027 - val_Encoder-Garbedge_loss: 0.0173 - val_Encoder-Output_loss: 1.8854\n",
      "Train on 4634 samples, validate on 244 samples\n",
      "Epoch 6301/6301\n",
      "4634/4634 [==============================] - 18s 4ms/step - loss: 7.1259 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.1124 - val_loss: 1.6205 - val_Encoder-Garbedge_loss: 0.0100 - val_Encoder-Output_loss: 1.6106\n",
      "Train on 3845 samples, validate on 203 samples\n",
      "Epoch 6321/6321\n",
      "3845/3845 [==============================] - 15s 4ms/step - loss: 6.7727 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 6.7589 - val_loss: 1.7128 - val_Encoder-Garbedge_loss: 0.0131 - val_Encoder-Output_loss: 1.6997\n",
      "Train on 4028 samples, validate on 212 samples\n",
      "Epoch 6341/6341\n",
      "4028/4028 [==============================] - 15s 4ms/step - loss: 7.9668 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.9535 - val_loss: 1.7437 - val_Encoder-Garbedge_loss: 0.0128 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 1936 samples, validate on 102 samples\n",
      "Epoch 6361/6361\n",
      "1936/1936 [==============================] - 7s 4ms/step - loss: 10.7254 - Encoder-Garbedge_loss: 0.0139 - Encoder-Output_loss: 10.7116 - val_loss: 1.8990 - val_Encoder-Garbedge_loss: 0.0137 - val_Encoder-Output_loss: 1.8853\n",
      "Train on 4712 samples, validate on 249 samples\n",
      "Epoch 6381/6381\n",
      "4712/4712 [==============================] - 18s 4ms/step - loss: 6.9091 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 6.8960 - val_loss: 1.6177 - val_Encoder-Garbedge_loss: 0.0104 - val_Encoder-Output_loss: 1.6074\n",
      "Train on 4750 samples, validate on 251 samples\n",
      "Epoch 6401/6401\n",
      "4750/4750 [==============================] - 18s 4ms/step - loss: 8.0532 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 8.0396 - val_loss: 1.7115 - val_Encoder-Garbedge_loss: 0.0102 - val_Encoder-Output_loss: 1.7014\n",
      "Train on 5252 samples, validate on 277 samples\n",
      "Epoch 6421/6421\n",
      "5252/5252 [==============================] - 20s 4ms/step - loss: 6.1112 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.0979 - val_loss: 1.7721 - val_Encoder-Garbedge_loss: 0.0103 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4396 samples, validate on 232 samples\n",
      "Epoch 6441/6441\n",
      "4396/4396 [==============================] - 17s 4ms/step - loss: 6.8569 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 6.8434 - val_loss: 1.7738 - val_Encoder-Garbedge_loss: 0.0120 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4576 samples, validate on 241 samples\n",
      "Epoch 6461/6461\n",
      "4576/4576 [==============================] - 18s 4ms/step - loss: 7.0528 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 7.0392 - val_loss: 1.6503 - val_Encoder-Garbedge_loss: 0.0121 - val_Encoder-Output_loss: 1.6381\n",
      "Train on 5312 samples, validate on 280 samples\n",
      "Epoch 6481/6481\n",
      "5312/5312 [==============================] - 20s 4ms/step - loss: 6.1046 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.0914 - val_loss: 1.6474 - val_Encoder-Garbedge_loss: 0.0095 - val_Encoder-Output_loss: 1.6379\n",
      "Train on 5139 samples, validate on 271 samples\n",
      "Epoch 6501/6501\n",
      "5139/5139 [==============================] - 18s 4ms/step - loss: 9.2865 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 9.2731 - val_loss: 1.9903 - val_Encoder-Garbedge_loss: 0.0121 - val_Encoder-Output_loss: 1.9782\n",
      "\n",
      "\n",
      "Train on 3935 samples, validate on 208 samples\n",
      "Epoch 6521/6521\n",
      "3935/3935 [==============================] - 14s 4ms/step - loss: 7.0553 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 7.0417 - val_loss: 1.8649 - val_Encoder-Garbedge_loss: 0.0104 - val_Encoder-Output_loss: 1.8545\n",
      "Train on 4031 samples, validate on 213 samples\n",
      "Epoch 6541/6541\n",
      "4031/4031 [==============================] - 14s 4ms/step - loss: 7.0906 - Encoder-Garbedge_loss: 0.0129 - Encoder-Output_loss: 7.0777 - val_loss: 1.6467 - val_Encoder-Garbedge_loss: 0.0085 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 3729 samples, validate on 197 samples\n",
      "Epoch 6561/6561\n",
      "3729/3729 [==============================] - 13s 4ms/step - loss: 6.5026 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.4894 - val_loss: 1.7381 - val_Encoder-Garbedge_loss: 0.0171 - val_Encoder-Output_loss: 1.7210\n",
      "Train on 4362 samples, validate on 230 samples\n",
      "Epoch 6581/6581\n",
      "4362/4362 [==============================] - 16s 4ms/step - loss: 7.6065 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.5932 - val_loss: 1.8081 - val_Encoder-Garbedge_loss: 0.0153 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 3657 samples, validate on 193 samples\n",
      "Epoch 6601/6601\n",
      "3657/3657 [==============================] - 13s 4ms/step - loss: 9.0382 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 9.0247 - val_loss: 1.8389 - val_Encoder-Garbedge_loss: 0.0153 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 4241 samples, validate on 224 samples\n",
      "Epoch 6621/6621\n",
      "4241/4241 [==============================] - 15s 4ms/step - loss: 6.6994 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.6862 - val_loss: 1.6565 - val_Encoder-Garbedge_loss: 0.0186 - val_Encoder-Output_loss: 1.6379\n",
      "Train on 2373 samples, validate on 125 samples\n",
      "Epoch 6641/6641\n",
      "2373/2373 [==============================] - 8s 4ms/step - loss: 5.4084 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 5.3948 - val_loss: 1.7123 - val_Encoder-Garbedge_loss: 0.0123 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4390 samples, validate on 232 samples\n",
      "Epoch 6661/6661\n",
      "4390/4390 [==============================] - 16s 4ms/step - loss: 7.5959 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 7.5822 - val_loss: 1.6502 - val_Encoder-Garbedge_loss: 0.0120 - val_Encoder-Output_loss: 1.6382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4099 samples, validate on 216 samples\n",
      "Epoch 6681/6681\n",
      "4099/4099 [==============================] - 14s 4ms/step - loss: 7.6528 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.6393 - val_loss: 1.7748 - val_Encoder-Garbedge_loss: 0.0133 - val_Encoder-Output_loss: 1.7615\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 6701/6701\n",
      "4006/4006 [==============================] - 15s 4ms/step - loss: 9.1411 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 9.1276 - val_loss: 1.7105 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4707 samples, validate on 248 samples\n",
      "Epoch 6721/6721\n",
      "4707/4707 [==============================] - 18s 4ms/step - loss: 6.5118 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.4983 - val_loss: 1.8056 - val_Encoder-Garbedge_loss: 0.0129 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 2228 samples, validate on 118 samples\n",
      "Epoch 6741/6741\n",
      "2228/2228 [==============================] - 8s 4ms/step - loss: 9.5823 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 9.5687 - val_loss: 1.8357 - val_Encoder-Garbedge_loss: 0.0122 - val_Encoder-Output_loss: 1.8235\n",
      "Train on 4584 samples, validate on 242 samples\n",
      "Epoch 6761/6761\n",
      "4584/4584 [==============================] - 18s 4ms/step - loss: 6.4810 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.4678 - val_loss: 1.5244 - val_Encoder-Garbedge_loss: 0.0101 - val_Encoder-Output_loss: 1.5143\n",
      "Train on 4290 samples, validate on 226 samples\n",
      "Epoch 6781/6781\n",
      "4290/4290 [==============================] - 16s 4ms/step - loss: 7.1741 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 7.1604 - val_loss: 2.1480 - val_Encoder-Garbedge_loss: 0.0153 - val_Encoder-Output_loss: 2.1327\n",
      "Train on 3598 samples, validate on 190 samples\n",
      "Epoch 6801/6801\n",
      "3598/3598 [==============================] - 13s 4ms/step - loss: 6.5891 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 6.5759 - val_loss: 1.8365 - val_Encoder-Garbedge_loss: 0.0129 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 4768 samples, validate on 251 samples\n",
      "Epoch 6821/6821\n",
      "4768/4768 [==============================] - 17s 4ms/step - loss: 7.0324 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.0189 - val_loss: 1.8968 - val_Encoder-Garbedge_loss: 0.0089 - val_Encoder-Output_loss: 1.8880\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 6841/6841\n",
      "4006/4006 [==============================] - 14s 4ms/step - loss: 8.9509 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 8.9379 - val_loss: 1.5873 - val_Encoder-Garbedge_loss: 0.0110 - val_Encoder-Output_loss: 1.5764\n",
      "Train on 3825 samples, validate on 202 samples\n",
      "Epoch 6861/6861\n",
      "3825/3825 [==============================] - 14s 4ms/step - loss: 7.5611 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.5479 - val_loss: 1.5898 - val_Encoder-Garbedge_loss: 0.0134 - val_Encoder-Output_loss: 1.5763\n",
      "Train on 5114 samples, validate on 270 samples\n",
      "Epoch 6881/6881\n",
      "5114/5114 [==============================] - 19s 4ms/step - loss: 7.6735 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.6603 - val_loss: 1.7731 - val_Encoder-Garbedge_loss: 0.0112 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4485 samples, validate on 237 samples\n",
      "Epoch 6901/6901\n",
      "4485/4485 [==============================] - 16s 4ms/step - loss: 6.9316 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 6.9186 - val_loss: 1.5585 - val_Encoder-Garbedge_loss: 0.0130 - val_Encoder-Output_loss: 1.5454\n",
      "Train on 5190 samples, validate on 274 samples\n",
      "Epoch 6921/6921\n",
      "5190/5190 [==============================] - 19s 4ms/step - loss: 7.1637 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.1504 - val_loss: 1.6814 - val_Encoder-Garbedge_loss: 0.0123 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 3797 samples, validate on 200 samples\n",
      "Epoch 6941/6941\n",
      "3797/3797 [==============================] - 14s 4ms/step - loss: 5.8646 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 5.8512 - val_loss: 1.7258 - val_Encoder-Garbedge_loss: 0.0117 - val_Encoder-Output_loss: 1.7141\n",
      "Train on 4964 samples, validate on 262 samples\n",
      "Epoch 6961/6961\n",
      "4964/4964 [==============================] - 18s 4ms/step - loss: 5.6042 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 5.5905 - val_loss: 1.9600 - val_Encoder-Garbedge_loss: 0.0127 - val_Encoder-Output_loss: 1.9473\n",
      "Train on 5469 samples, validate on 288 samples\n",
      "Epoch 6981/6981\n",
      "5469/5469 [==============================] - 19s 4ms/step - loss: 7.1775 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.1641 - val_loss: 1.8074 - val_Encoder-Garbedge_loss: 0.0147 - val_Encoder-Output_loss: 1.7927\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 7\n",
      "**********************************\n",
      "\n",
      "Train on 4323 samples, validate on 228 samples\n",
      "Epoch 7001/7001\n",
      "4323/4323 [==============================] - 15s 4ms/step - loss: 6.6752 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.6617 - val_loss: 1.6218 - val_Encoder-Garbedge_loss: 0.0119 - val_Encoder-Output_loss: 1.6099\n",
      "\n",
      "\n",
      "Train on 2870 samples, validate on 152 samples\n",
      "Epoch 7021/7021\n",
      "2870/2870 [==============================] - 10s 4ms/step - loss: 10.4085 - Encoder-Garbedge_loss: 0.0128 - Encoder-Output_loss: 10.3957 - val_loss: 1.8017 - val_Encoder-Garbedge_loss: 0.0090 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 5088 samples, validate on 268 samples\n",
      "Epoch 7041/7041\n",
      "5088/5088 [==============================] - 18s 4ms/step - loss: 7.5948 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 7.5811 - val_loss: 1.7399 - val_Encoder-Garbedge_loss: 0.0090 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 4287 samples, validate on 226 samples\n",
      "Epoch 7061/7061\n",
      "4287/4287 [==============================] - 15s 4ms/step - loss: 9.4056 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 9.3921 - val_loss: 1.7103 - val_Encoder-Garbedge_loss: 0.0106 - val_Encoder-Output_loss: 1.6997\n",
      "Train on 3027 samples, validate on 160 samples\n",
      "Epoch 7081/7081\n",
      "3027/3027 [==============================] - 11s 4ms/step - loss: 7.9274 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.9140 - val_loss: 4.5998 - val_Encoder-Garbedge_loss: 0.0121 - val_Encoder-Output_loss: 4.5878\n",
      "Train on 4067 samples, validate on 215 samples\n",
      "Epoch 7101/7101\n",
      "4067/4067 [==============================] - 14s 4ms/step - loss: 7.1972 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.1838 - val_loss: 2.7331 - val_Encoder-Garbedge_loss: 0.0119 - val_Encoder-Output_loss: 2.7212\n",
      "Train on 5628 samples, validate on 297 samples\n",
      "Epoch 7121/7121\n",
      "5628/5628 [==============================] - 20s 4ms/step - loss: 8.0327 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 8.0190 - val_loss: 1.5898 - val_Encoder-Garbedge_loss: 0.0120 - val_Encoder-Output_loss: 1.5778\n",
      "Train on 4883 samples, validate on 257 samples\n",
      "Epoch 7141/7141\n",
      "4883/4883 [==============================] - 17s 4ms/step - loss: 7.8028 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.7895 - val_loss: 1.8349 - val_Encoder-Garbedge_loss: 0.0109 - val_Encoder-Output_loss: 1.8241\n",
      "Train on 4391 samples, validate on 232 samples\n",
      "Epoch 7161/7161\n",
      "4391/4391 [==============================] - 16s 4ms/step - loss: 5.8475 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 5.8342 - val_loss: 1.8051 - val_Encoder-Garbedge_loss: 0.0125 - val_Encoder-Output_loss: 1.7926\n",
      "Train on 5474 samples, validate on 289 samples\n",
      "Epoch 7181/7181\n",
      "5474/5474 [==============================] - 19s 4ms/step - loss: 7.2681 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.2548 - val_loss: 1.6833 - val_Encoder-Garbedge_loss: 0.0142 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 4681 samples, validate on 247 samples\n",
      "Epoch 7201/7201\n",
      "4681/4681 [==============================] - 17s 4ms/step - loss: 6.3064 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.2932 - val_loss: 2.7530 - val_Encoder-Garbedge_loss: 0.0175 - val_Encoder-Output_loss: 2.7355\n",
      "Train on 4414 samples, validate on 233 samples\n",
      "Epoch 7221/7221\n",
      "4414/4414 [==============================] - 16s 4ms/step - loss: 7.6294 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 7.6164 - val_loss: 1.8039 - val_Encoder-Garbedge_loss: 0.0112 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 6049 samples, validate on 319 samples\n",
      "Epoch 7241/7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6049/6049 [==============================] - 22s 4ms/step - loss: 8.4247 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 8.4115 - val_loss: 1.8459 - val_Encoder-Garbedge_loss: 0.0222 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 4440 samples, validate on 234 samples\n",
      "Epoch 7261/7261\n",
      "4440/4440 [==============================] - 16s 4ms/step - loss: 6.3016 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 6.2879 - val_loss: 1.6501 - val_Encoder-Garbedge_loss: 0.0119 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 4445 samples, validate on 234 samples\n",
      "Epoch 7281/7281\n",
      "4445/4445 [==============================] - 16s 4ms/step - loss: 7.5697 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.5563 - val_loss: 1.8832 - val_Encoder-Garbedge_loss: 0.0114 - val_Encoder-Output_loss: 1.8718\n",
      "Train on 4634 samples, validate on 244 samples\n",
      "Epoch 7301/7301\n",
      "4634/4634 [==============================] - 16s 4ms/step - loss: 7.0218 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.0086 - val_loss: 1.6796 - val_Encoder-Garbedge_loss: 0.0106 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 3845 samples, validate on 203 samples\n",
      "Epoch 7321/7321\n",
      "3845/3845 [==============================] - 14s 4ms/step - loss: 6.7800 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.7667 - val_loss: 1.7172 - val_Encoder-Garbedge_loss: 0.0172 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4028 samples, validate on 212 samples\n",
      "Epoch 7341/7341\n",
      "4028/4028 [==============================] - 14s 4ms/step - loss: 8.0528 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 8.0397 - val_loss: 1.7411 - val_Encoder-Garbedge_loss: 0.0102 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 1936 samples, validate on 102 samples\n",
      "Epoch 7361/7361\n",
      "1936/1936 [==============================] - 7s 4ms/step - loss: 10.8011 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 10.7878 - val_loss: 1.9594 - val_Encoder-Garbedge_loss: 0.0124 - val_Encoder-Output_loss: 1.9470\n",
      "Train on 4712 samples, validate on 249 samples\n",
      "Epoch 7381/7381\n",
      "4712/4712 [==============================] - 17s 4ms/step - loss: 6.9693 - Encoder-Garbedge_loss: 0.0128 - Encoder-Output_loss: 6.9565 - val_loss: 1.6807 - val_Encoder-Garbedge_loss: 0.0116 - val_Encoder-Output_loss: 1.6690\n",
      "Train on 4750 samples, validate on 251 samples\n",
      "Epoch 7401/7401\n",
      "4750/4750 [==============================] - 17s 4ms/step - loss: 7.8696 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.8561 - val_loss: 1.6489 - val_Encoder-Garbedge_loss: 0.0106 - val_Encoder-Output_loss: 1.6383\n",
      "Train on 5252 samples, validate on 277 samples\n",
      "Epoch 7421/7421\n",
      "5252/5252 [==============================] - 19s 4ms/step - loss: 6.1886 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.1753 - val_loss: 1.7111 - val_Encoder-Garbedge_loss: 0.0111 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4396 samples, validate on 232 samples\n",
      "Epoch 7441/7441\n",
      "4396/4396 [==============================] - 16s 4ms/step - loss: 6.9177 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 6.9041 - val_loss: 1.7780 - val_Encoder-Garbedge_loss: 0.0100 - val_Encoder-Output_loss: 1.7680\n",
      "Train on 4576 samples, validate on 241 samples\n",
      "Epoch 7461/7461\n",
      "4576/4576 [==============================] - 16s 4ms/step - loss: 7.0403 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.0272 - val_loss: 1.6175 - val_Encoder-Garbedge_loss: 0.0104 - val_Encoder-Output_loss: 1.6072\n",
      "Train on 5312 samples, validate on 280 samples\n",
      "Epoch 7481/7481\n",
      "5312/5312 [==============================] - 19s 4ms/step - loss: 6.0609 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.0477 - val_loss: 1.4953 - val_Encoder-Garbedge_loss: 0.0114 - val_Encoder-Output_loss: 1.4839\n",
      "Train on 5139 samples, validate on 271 samples\n",
      "Epoch 7501/7501\n",
      "5139/5139 [==============================] - 18s 4ms/step - loss: 9.3711 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 9.3578 - val_loss: 1.8925 - val_Encoder-Garbedge_loss: 0.0108 - val_Encoder-Output_loss: 1.8817\n",
      "\n",
      "\n",
      "Train on 3935 samples, validate on 208 samples\n",
      "Epoch 7521/7521\n",
      "3935/3935 [==============================] - 14s 4ms/step - loss: 6.8508 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.8376 - val_loss: 1.7723 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4031 samples, validate on 213 samples\n",
      "Epoch 7541/7541\n",
      "4031/4031 [==============================] - 14s 4ms/step - loss: 7.0743 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.0612 - val_loss: 1.6512 - val_Encoder-Garbedge_loss: 0.0121 - val_Encoder-Output_loss: 1.6391\n",
      "Train on 3729 samples, validate on 197 samples\n",
      "Epoch 7561/7561\n",
      "3729/3729 [==============================] - 13s 4ms/step - loss: 6.5499 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.5366 - val_loss: 1.6861 - val_Encoder-Garbedge_loss: 0.0170 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 4362 samples, validate on 230 samples\n",
      "Epoch 7581/7581\n",
      "4362/4362 [==============================] - 15s 4ms/step - loss: 7.6419 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.6286 - val_loss: 1.8974 - val_Encoder-Garbedge_loss: 0.0120 - val_Encoder-Output_loss: 1.8854\n",
      "Train on 3657 samples, validate on 193 samples\n",
      "Epoch 7601/7601\n",
      "3657/3657 [==============================] - 13s 4ms/step - loss: 8.8948 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 8.8815 - val_loss: 1.7775 - val_Encoder-Garbedge_loss: 0.0159 - val_Encoder-Output_loss: 1.7617\n",
      "Train on 4241 samples, validate on 224 samples\n",
      "Epoch 7621/7621\n",
      "4241/4241 [==============================] - 15s 4ms/step - loss: 6.8367 - Encoder-Garbedge_loss: 0.0129 - Encoder-Output_loss: 6.8238 - val_loss: 1.7466 - val_Encoder-Garbedge_loss: 0.0149 - val_Encoder-Output_loss: 1.7316\n",
      "Train on 2373 samples, validate on 125 samples\n",
      "Epoch 7641/7641\n",
      "2373/2373 [==============================] - 9s 4ms/step - loss: 5.4527 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 5.4397 - val_loss: 1.7510 - val_Encoder-Garbedge_loss: 0.0201 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 4390 samples, validate on 232 samples\n",
      "Epoch 7661/7661\n",
      "4390/4390 [==============================] - 15s 4ms/step - loss: 7.5488 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.5356 - val_loss: 2.4767 - val_Encoder-Garbedge_loss: 0.0108 - val_Encoder-Output_loss: 2.4659\n",
      "Train on 4099 samples, validate on 216 samples\n",
      "Epoch 7681/7681\n",
      "4099/4099 [==============================] - 14s 4ms/step - loss: 7.7483 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.7349 - val_loss: 1.8347 - val_Encoder-Garbedge_loss: 0.0112 - val_Encoder-Output_loss: 1.8235\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 7701/7701\n",
      "4006/4006 [==============================] - 14s 4ms/step - loss: 9.0903 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 9.0770 - val_loss: 3.7699 - val_Encoder-Garbedge_loss: 0.0138 - val_Encoder-Output_loss: 3.7561\n",
      "Train on 4707 samples, validate on 248 samples\n",
      "Epoch 7721/7721\n",
      "4707/4707 [==============================] - 17s 4ms/step - loss: 6.5046 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.4913 - val_loss: 1.7143 - val_Encoder-Garbedge_loss: 0.0143 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 2228 samples, validate on 118 samples\n",
      "Epoch 7741/7741\n",
      "2228/2228 [==============================] - 8s 4ms/step - loss: 9.6536 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 9.6402 - val_loss: 1.8964 - val_Encoder-Garbedge_loss: 0.0109 - val_Encoder-Output_loss: 1.8855\n",
      "Train on 4584 samples, validate on 242 samples\n",
      "Epoch 7761/7761\n",
      "4584/4584 [==============================] - 16s 4ms/step - loss: 6.6173 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 6.6035 - val_loss: 1.7153 - val_Encoder-Garbedge_loss: 0.0153 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4290 samples, validate on 226 samples\n",
      "Epoch 7781/7781\n",
      "4290/4290 [==============================] - 15s 4ms/step - loss: 7.0359 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.0226 - val_loss: 2.0222 - val_Encoder-Garbedge_loss: 0.0131 - val_Encoder-Output_loss: 2.0091\n",
      "Train on 3598 samples, validate on 190 samples\n",
      "Epoch 7801/7801\n",
      "3598/3598 [==============================] - 13s 3ms/step - loss: 6.5711 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 6.5581 - val_loss: 1.7722 - val_Encoder-Garbedge_loss: 0.0108 - val_Encoder-Output_loss: 1.7614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4768 samples, validate on 251 samples\n",
      "Epoch 7821/7821\n",
      "4768/4768 [==============================] - 17s 4ms/step - loss: 7.1702 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.1570 - val_loss: 1.9254 - val_Encoder-Garbedge_loss: 0.0090 - val_Encoder-Output_loss: 1.9163\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 7841/7841\n",
      "4006/4006 [==============================] - 14s 4ms/step - loss: 8.9829 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 8.9694 - val_loss: 1.5963 - val_Encoder-Garbedge_loss: 0.0165 - val_Encoder-Output_loss: 1.5798\n",
      "Train on 3825 samples, validate on 202 samples\n",
      "Epoch 7861/7861\n",
      "3825/3825 [==============================] - 14s 4ms/step - loss: 7.6115 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.5983 - val_loss: 1.6534 - val_Encoder-Garbedge_loss: 0.0152 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 5114 samples, validate on 270 samples\n",
      "Epoch 7881/7881\n",
      "5114/5114 [==============================] - 18s 4ms/step - loss: 7.7110 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.6975 - val_loss: 1.8734 - val_Encoder-Garbedge_loss: 0.0134 - val_Encoder-Output_loss: 1.8600\n",
      "Train on 4485 samples, validate on 237 samples\n",
      "Epoch 7901/7901\n",
      "4485/4485 [==============================] - 16s 4ms/step - loss: 7.0531 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.0397 - val_loss: 1.6825 - val_Encoder-Garbedge_loss: 0.0135 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 5190 samples, validate on 274 samples\n",
      "Epoch 7921/7921\n",
      "5190/5190 [==============================] - 19s 4ms/step - loss: 7.1292 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.1161 - val_loss: 1.6841 - val_Encoder-Garbedge_loss: 0.0152 - val_Encoder-Output_loss: 1.6689\n",
      "Train on 3797 samples, validate on 200 samples\n",
      "Epoch 7941/7941\n",
      "3797/3797 [==============================] - 14s 4ms/step - loss: 5.8616 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 5.8484 - val_loss: 1.6562 - val_Encoder-Garbedge_loss: 0.0180 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 4964 samples, validate on 262 samples\n",
      "Epoch 7961/7961\n",
      "4964/4964 [==============================] - 18s 4ms/step - loss: 5.6719 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 5.6583 - val_loss: 1.9256 - val_Encoder-Garbedge_loss: 0.0091 - val_Encoder-Output_loss: 1.9164\n",
      "Train on 5469 samples, validate on 288 samples\n",
      "Epoch 7981/7981\n",
      "5469/5469 [==============================] - 19s 4ms/step - loss: 6.9631 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.9498 - val_loss: 1.8081 - val_Encoder-Garbedge_loss: 0.0154 - val_Encoder-Output_loss: 1.7927\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 8\n",
      "**********************************\n",
      "\n",
      "Train on 4323 samples, validate on 228 samples\n",
      "Epoch 8001/8001\n",
      "4323/4323 [==============================] - 15s 4ms/step - loss: 6.7175 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.7041 - val_loss: 1.6808 - val_Encoder-Garbedge_loss: 0.0117 - val_Encoder-Output_loss: 1.6691\n",
      "\n",
      "\n",
      "Train on 2870 samples, validate on 152 samples\n",
      "Epoch 8021/8021\n",
      "2870/2870 [==============================] - 10s 4ms/step - loss: 10.3844 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 10.3710 - val_loss: 1.7756 - val_Encoder-Garbedge_loss: 0.0138 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 5088 samples, validate on 268 samples\n",
      "Epoch 8041/8041\n",
      "5088/5088 [==============================] - 18s 4ms/step - loss: 7.5927 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.5796 - val_loss: 1.8039 - val_Encoder-Garbedge_loss: 0.0112 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 4287 samples, validate on 226 samples\n",
      "Epoch 8061/8061\n",
      "4287/4287 [==============================] - 15s 4ms/step - loss: 9.3602 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 9.3469 - val_loss: 1.5888 - val_Encoder-Garbedge_loss: 0.0125 - val_Encoder-Output_loss: 1.5763\n",
      "Train on 3027 samples, validate on 160 samples\n",
      "Epoch 8081/8081\n",
      "3027/3027 [==============================] - 11s 4ms/step - loss: 8.1264 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 8.1128 - val_loss: 1.7743 - val_Encoder-Garbedge_loss: 0.0125 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4067 samples, validate on 215 samples\n",
      "Epoch 8101/8101\n",
      "4067/4067 [==============================] - 15s 4ms/step - loss: 7.2446 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.2315 - val_loss: 1.7416 - val_Encoder-Garbedge_loss: 0.0107 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 5628 samples, validate on 297 samples\n",
      "Epoch 8121/8121\n",
      "5628/5628 [==============================] - 20s 4ms/step - loss: 8.0671 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 8.0538 - val_loss: 1.7705 - val_Encoder-Garbedge_loss: 0.0092 - val_Encoder-Output_loss: 1.7613\n",
      "Train on 4883 samples, validate on 257 samples\n",
      "Epoch 8141/8141\n",
      "4883/4883 [==============================] - 17s 4ms/step - loss: 7.8925 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.8792 - val_loss: 1.9611 - val_Encoder-Garbedge_loss: 0.0123 - val_Encoder-Output_loss: 1.9488\n",
      "Train on 4391 samples, validate on 232 samples\n",
      "Epoch 8161/8161\n",
      "4391/4391 [==============================] - 16s 4ms/step - loss: 5.7945 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 5.7810 - val_loss: 1.7766 - val_Encoder-Garbedge_loss: 0.0144 - val_Encoder-Output_loss: 1.7621\n",
      "Train on 5474 samples, validate on 289 samples\n",
      "Epoch 8181/8181\n",
      "5474/5474 [==============================] - 19s 4ms/step - loss: 7.2281 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.2148 - val_loss: 1.6515 - val_Encoder-Garbedge_loss: 0.0133 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 4681 samples, validate on 247 samples\n",
      "Epoch 8201/8201\n",
      "4681/4681 [==============================] - 17s 4ms/step - loss: 6.3257 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.3124 - val_loss: 1.7785 - val_Encoder-Garbedge_loss: 0.0166 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4414 samples, validate on 233 samples\n",
      "Epoch 8221/8221\n",
      "4414/4414 [==============================] - 16s 4ms/step - loss: 7.5418 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.5284 - val_loss: 1.7115 - val_Encoder-Garbedge_loss: 0.0115 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 6049 samples, validate on 319 samples\n",
      "Epoch 8241/8241\n",
      "6049/6049 [==============================] - 21s 4ms/step - loss: 8.3189 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 8.3056 - val_loss: 1.8464 - val_Encoder-Garbedge_loss: 0.0149 - val_Encoder-Output_loss: 1.8315\n",
      "Train on 4440 samples, validate on 234 samples\n",
      "Epoch 8261/8261\n",
      "4440/4440 [==============================] - 16s 4ms/step - loss: 6.3780 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.3647 - val_loss: 1.7445 - val_Encoder-Garbedge_loss: 0.0135 - val_Encoder-Output_loss: 1.7310\n",
      "Train on 4445 samples, validate on 234 samples\n",
      "Epoch 8281/8281\n",
      "4445/4445 [==============================] - 16s 4ms/step - loss: 7.5816 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.5681 - val_loss: 1.8723 - val_Encoder-Garbedge_loss: 0.0177 - val_Encoder-Output_loss: 1.8546\n",
      "Train on 4634 samples, validate on 244 samples\n",
      "Epoch 8301/8301\n",
      "4634/4634 [==============================] - 17s 4ms/step - loss: 7.1376 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.1243 - val_loss: 1.7442 - val_Encoder-Garbedge_loss: 0.0133 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 3845 samples, validate on 203 samples\n",
      "Epoch 8321/8321\n",
      "3845/3845 [==============================] - 14s 4ms/step - loss: 6.7152 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.7018 - val_loss: 8.2365 - val_Encoder-Garbedge_loss: 0.0158 - val_Encoder-Output_loss: 8.2207\n",
      "Train on 4028 samples, validate on 212 samples\n",
      "Epoch 8341/8341\n",
      "4028/4028 [==============================] - 14s 4ms/step - loss: 8.0031 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 7.9900 - val_loss: 1.7773 - val_Encoder-Garbedge_loss: 0.0160 - val_Encoder-Output_loss: 1.7613\n",
      "Train on 1936 samples, validate on 102 samples\n",
      "Epoch 8361/8361\n",
      "1936/1936 [==============================] - 7s 4ms/step - loss: 10.9038 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 10.8905 - val_loss: 2.0261 - val_Encoder-Garbedge_loss: 0.0111 - val_Encoder-Output_loss: 2.0150\n",
      "Train on 4712 samples, validate on 249 samples\n",
      "Epoch 8381/8381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4712/4712 [==============================] - 17s 4ms/step - loss: 7.0344 - Encoder-Garbedge_loss: 0.0128 - Encoder-Output_loss: 7.0216 - val_loss: 1.8341 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 4750 samples, validate on 251 samples\n",
      "Epoch 8401/8401\n",
      "4750/4750 [==============================] - 17s 4ms/step - loss: 8.0912 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 8.0777 - val_loss: 1.7407 - val_Encoder-Garbedge_loss: 0.0097 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 5252 samples, validate on 277 samples\n",
      "Epoch 8421/8421\n",
      "5252/5252 [==============================] - 19s 4ms/step - loss: 6.1486 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.1352 - val_loss: 1.6194 - val_Encoder-Garbedge_loss: 0.0122 - val_Encoder-Output_loss: 1.6072\n",
      "Train on 4396 samples, validate on 232 samples\n",
      "Epoch 8441/8441\n",
      "4396/4396 [==============================] - 16s 4ms/step - loss: 6.8545 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.8409 - val_loss: 1.8343 - val_Encoder-Garbedge_loss: 0.0111 - val_Encoder-Output_loss: 1.8232\n",
      "Train on 4576 samples, validate on 241 samples\n",
      "Epoch 8461/8461\n",
      "4576/4576 [==============================] - 17s 4ms/step - loss: 7.0750 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.0615 - val_loss: 1.7222 - val_Encoder-Garbedge_loss: 0.0117 - val_Encoder-Output_loss: 1.7105\n",
      "Train on 5312 samples, validate on 280 samples\n",
      "Epoch 8481/8481\n",
      "5312/5312 [==============================] - 19s 4ms/step - loss: 6.0335 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.0202 - val_loss: 1.5868 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 1.5764\n",
      "Train on 5139 samples, validate on 271 samples\n",
      "Epoch 8501/8501\n",
      "5139/5139 [==============================] - 18s 4ms/step - loss: 9.3233 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 9.3100 - val_loss: 1.8988 - val_Encoder-Garbedge_loss: 0.0136 - val_Encoder-Output_loss: 1.8853\n",
      "\n",
      "\n",
      "Train on 3935 samples, validate on 208 samples\n",
      "Epoch 8521/8521\n",
      "3935/3935 [==============================] - 14s 4ms/step - loss: 6.8998 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 6.8862 - val_loss: 1.8057 - val_Encoder-Garbedge_loss: 0.0130 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 4031 samples, validate on 213 samples\n",
      "Epoch 8541/8541\n",
      "4031/4031 [==============================] - 14s 4ms/step - loss: 7.1982 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.1851 - val_loss: 1.7749 - val_Encoder-Garbedge_loss: 0.0131 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 3729 samples, validate on 197 samples\n",
      "Epoch 8561/8561\n",
      "3729/3729 [==============================] - 13s 4ms/step - loss: 6.6877 - Encoder-Garbedge_loss: 0.0129 - Encoder-Output_loss: 6.6748 - val_loss: 1.8386 - val_Encoder-Garbedge_loss: 0.0150 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 4362 samples, validate on 230 samples\n",
      "Epoch 8581/8581\n",
      "4362/4362 [==============================] - 16s 4ms/step - loss: 7.6196 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.6061 - val_loss: 1.8362 - val_Encoder-Garbedge_loss: 0.0126 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 3657 samples, validate on 193 samples\n",
      "Epoch 8601/8601\n",
      "3657/3657 [==============================] - 13s 4ms/step - loss: 8.8964 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 8.8829 - val_loss: 2.6872 - val_Encoder-Garbedge_loss: 0.0177 - val_Encoder-Output_loss: 2.6696\n",
      "Train on 4241 samples, validate on 224 samples\n",
      "Epoch 8621/8621\n",
      "4241/4241 [==============================] - 15s 4ms/step - loss: 7.0275 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.0142 - val_loss: 1.9291 - val_Encoder-Garbedge_loss: 0.0128 - val_Encoder-Output_loss: 1.9163\n",
      "Train on 2373 samples, validate on 125 samples\n",
      "Epoch 8641/8641\n",
      "2373/2373 [==============================] - 9s 4ms/step - loss: 5.3854 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 5.3721 - val_loss: 1.7166 - val_Encoder-Garbedge_loss: 0.0166 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4390 samples, validate on 232 samples\n",
      "Epoch 8661/8661\n",
      "4390/4390 [==============================] - 16s 4ms/step - loss: 7.6497 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.6363 - val_loss: 1.6800 - val_Encoder-Garbedge_loss: 0.0092 - val_Encoder-Output_loss: 1.6708\n",
      "Train on 4099 samples, validate on 216 samples\n",
      "Epoch 8681/8681\n",
      "4099/4099 [==============================] - 15s 4ms/step - loss: 7.6087 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.5955 - val_loss: 1.5877 - val_Encoder-Garbedge_loss: 0.0114 - val_Encoder-Output_loss: 1.5763\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 8701/8701\n",
      "4006/4006 [==============================] - 14s 4ms/step - loss: 9.2777 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 9.2641 - val_loss: 2.0183 - val_Encoder-Garbedge_loss: 0.0140 - val_Encoder-Output_loss: 2.0043\n",
      "Train on 4707 samples, validate on 248 samples\n",
      "Epoch 8721/8721\n",
      "4707/4707 [==============================] - 17s 4ms/step - loss: 6.4887 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 6.4751 - val_loss: 1.7119 - val_Encoder-Garbedge_loss: 0.0127 - val_Encoder-Output_loss: 1.6992\n",
      "Train on 2228 samples, validate on 118 samples\n",
      "Epoch 8741/8741\n",
      "2228/2228 [==============================] - 8s 4ms/step - loss: 9.4652 - Encoder-Garbedge_loss: 0.0138 - Encoder-Output_loss: 9.4513 - val_loss: 1.8051 - val_Encoder-Garbedge_loss: 0.0125 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 4584 samples, validate on 242 samples\n",
      "Epoch 8761/8761\n",
      "4584/4584 [==============================] - 16s 4ms/step - loss: 6.5702 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.5570 - val_loss: 1.6176 - val_Encoder-Garbedge_loss: 0.0104 - val_Encoder-Output_loss: 1.6073\n",
      "Train on 4290 samples, validate on 226 samples\n",
      "Epoch 8781/8781\n",
      "4290/4290 [==============================] - 15s 4ms/step - loss: 7.1924 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 7.1788 - val_loss: 2.1475 - val_Encoder-Garbedge_loss: 0.0148 - val_Encoder-Output_loss: 2.1327\n",
      "Train on 3598 samples, validate on 190 samples\n",
      "Epoch 8801/8801\n",
      "3598/3598 [==============================] - 13s 4ms/step - loss: 6.6776 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.6643 - val_loss: 1.9297 - val_Encoder-Garbedge_loss: 0.0133 - val_Encoder-Output_loss: 1.9164\n",
      "Train on 4768 samples, validate on 251 samples\n",
      "Epoch 8821/8821\n",
      "4768/4768 [==============================] - 17s 4ms/step - loss: 7.2119 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 7.1989 - val_loss: 1.9931 - val_Encoder-Garbedge_loss: 0.0115 - val_Encoder-Output_loss: 1.9816\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 8841/8841\n",
      "4006/4006 [==============================] - 14s 4ms/step - loss: 8.9633 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 8.9502 - val_loss: 1.5282 - val_Encoder-Garbedge_loss: 0.0123 - val_Encoder-Output_loss: 1.5159\n",
      "Train on 3825 samples, validate on 202 samples\n",
      "Epoch 8861/8861\n",
      "3825/3825 [==============================] - 14s 4ms/step - loss: 7.6751 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.6619 - val_loss: 1.6830 - val_Encoder-Garbedge_loss: 0.0139 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 5114 samples, validate on 270 samples\n",
      "Epoch 8881/8881\n",
      "5114/5114 [==============================] - 18s 4ms/step - loss: 7.7316 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.7183 - val_loss: 1.8969 - val_Encoder-Garbedge_loss: 0.0114 - val_Encoder-Output_loss: 1.8855\n",
      "Train on 4485 samples, validate on 237 samples\n",
      "Epoch 8901/8901\n",
      "4485/4485 [==============================] - 16s 4ms/step - loss: 7.0836 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.0703 - val_loss: 1.8102 - val_Encoder-Garbedge_loss: 0.0159 - val_Encoder-Output_loss: 1.7943\n",
      "Train on 5190 samples, validate on 274 samples\n",
      "Epoch 8921/8921\n",
      "5190/5190 [==============================] - 18s 4ms/step - loss: 7.1695 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.1560 - val_loss: 1.7103 - val_Encoder-Garbedge_loss: 0.0103 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 3797 samples, validate on 200 samples\n",
      "Epoch 8941/8941\n",
      "3797/3797 [==============================] - 14s 4ms/step - loss: 5.9612 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 5.9481 - val_loss: 1.7435 - val_Encoder-Garbedge_loss: 0.0126 - val_Encoder-Output_loss: 1.7309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4964 samples, validate on 262 samples\n",
      "Epoch 8961/8961\n",
      "4964/4964 [==============================] - 18s 4ms/step - loss: 5.6659 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 5.6526 - val_loss: 1.9865 - val_Encoder-Garbedge_loss: 0.0086 - val_Encoder-Output_loss: 1.9779\n",
      "Train on 5469 samples, validate on 288 samples\n",
      "Epoch 8981/8981\n",
      "5469/5469 [==============================] - 20s 4ms/step - loss: 7.0128 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.9996 - val_loss: 1.7861 - val_Encoder-Garbedge_loss: 0.0146 - val_Encoder-Output_loss: 1.7715der-Garbedge_loss: 0.0132 - Encoder-Outp\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 9\n",
      "**********************************\n",
      "\n",
      "Train on 4323 samples, validate on 228 samples\n",
      "Epoch 9001/9001\n",
      "4323/4323 [==============================] - 16s 4ms/step - loss: 6.6326 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.6194 - val_loss: 1.6797 - val_Encoder-Garbedge_loss: 0.0106 - val_Encoder-Output_loss: 1.6691\n",
      "\n",
      "\n",
      "Train on 2870 samples, validate on 152 samples\n",
      "Epoch 9021/9021\n",
      "2870/2870 [==============================] - 10s 4ms/step - loss: 10.2977 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 10.2846 - val_loss: 1.7114 - val_Encoder-Garbedge_loss: 0.0114 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 5088 samples, validate on 268 samples\n",
      "Epoch 9041/9041\n",
      "5088/5088 [==============================] - 18s 4ms/step - loss: 7.5843 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.5711 - val_loss: 1.8359 - val_Encoder-Garbedge_loss: 0.0123 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 4287 samples, validate on 226 samples\n",
      "Epoch 9061/9061\n",
      "4287/4287 [==============================] - 15s 4ms/step - loss: 9.3991 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 9.3858 - val_loss: 1.6208 - val_Encoder-Garbedge_loss: 0.0135 - val_Encoder-Output_loss: 1.6073\n",
      "Train on 3027 samples, validate on 160 samples\n",
      "Epoch 9081/9081\n",
      "3027/3027 [==============================] - 11s 4ms/step - loss: 8.1413 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 8.1278 - val_loss: 1.7729 - val_Encoder-Garbedge_loss: 0.0110 - val_Encoder-Output_loss: 1.7619\n",
      "Train on 4067 samples, validate on 215 samples\n",
      "Epoch 9101/9101\n",
      "4067/4067 [==============================] - 14s 4ms/step - loss: 7.1832 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.1700 - val_loss: 1.6501 - val_Encoder-Garbedge_loss: 0.0133 - val_Encoder-Output_loss: 1.6369\n",
      "Train on 5628 samples, validate on 297 samples\n",
      "Epoch 9121/9121\n",
      "5628/5628 [==============================] - 20s 4ms/step - loss: 8.1326 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 8.1193 - val_loss: 1.9016 - val_Encoder-Garbedge_loss: 0.0113 - val_Encoder-Output_loss: 1.8902\n",
      "Train on 4883 samples, validate on 257 samples\n",
      "Epoch 9141/9141\n",
      "4883/4883 [==============================] - 18s 4ms/step - loss: 7.7910 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.7778 - val_loss: 1.8655 - val_Encoder-Garbedge_loss: 0.0110 - val_Encoder-Output_loss: 1.8545\n",
      "Train on 4391 samples, validate on 232 samples\n",
      "Epoch 9161/9161\n",
      "4391/4391 [==============================] - 16s 4ms/step - loss: 5.6912 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 5.6781 - val_loss: 1.6486 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 5474 samples, validate on 289 samples\n",
      "Epoch 9181/9181\n",
      "5474/5474 [==============================] - 20s 4ms/step - loss: 7.2238 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.2106 - val_loss: 1.5877 - val_Encoder-Garbedge_loss: 0.0113 - val_Encoder-Output_loss: 1.5764\n",
      "Train on 4681 samples, validate on 247 samples\n",
      "Epoch 9201/9201\n",
      "4681/4681 [==============================] - 16s 4ms/step - loss: 6.3276 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.3143 - val_loss: 1.7569 - val_Encoder-Garbedge_loss: 0.0129 - val_Encoder-Output_loss: 1.7440\n",
      "Train on 4414 samples, validate on 233 samples\n",
      "Epoch 9221/9221\n",
      "4414/4414 [==============================] - 16s 4ms/step - loss: 7.5680 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.5549 - val_loss: 1.7436 - val_Encoder-Garbedge_loss: 0.0127 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 6049 samples, validate on 319 samples\n",
      "Epoch 9241/9241\n",
      "6049/6049 [==============================] - 22s 4ms/step - loss: 8.3519 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 8.3386 - val_loss: 1.8681 - val_Encoder-Garbedge_loss: 0.0132 - val_Encoder-Output_loss: 1.8549\n",
      "Train on 4440 samples, validate on 234 samples\n",
      "Epoch 9261/9261\n",
      "4440/4440 [==============================] - 16s 4ms/step - loss: 6.3517 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 6.3380 - val_loss: 1.6192 - val_Encoder-Garbedge_loss: 0.0119 - val_Encoder-Output_loss: 1.6073\n",
      "Train on 4445 samples, validate on 234 samples\n",
      "Epoch 9281/9281\n",
      "4445/4445 [==============================] - 16s 4ms/step - loss: 7.5345 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 7.5209 - val_loss: 1.8420 - val_Encoder-Garbedge_loss: 0.0184 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 4634 samples, validate on 244 samples\n",
      "Epoch 9301/9301\n",
      "4634/4634 [==============================] - 16s 4ms/step - loss: 7.2633 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.2498 - val_loss: 1.8370 - val_Encoder-Garbedge_loss: 0.0135 - val_Encoder-Output_loss: 1.8234\n",
      "Train on 3845 samples, validate on 203 samples\n",
      "Epoch 9321/9321\n",
      "3845/3845 [==============================] - 14s 4ms/step - loss: 6.8783 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.8648 - val_loss: 1.7526 - val_Encoder-Garbedge_loss: 0.0142 - val_Encoder-Output_loss: 1.7385\n",
      "Train on 4028 samples, validate on 212 samples\n",
      "Epoch 9341/9341\n",
      "4028/4028 [==============================] - 14s 4ms/step - loss: 8.0187 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 8.0054 - val_loss: 1.6805 - val_Encoder-Garbedge_loss: 0.0112 - val_Encoder-Output_loss: 1.6693\n",
      "Train on 1936 samples, validate on 102 samples\n",
      "Epoch 9361/9361\n",
      "1936/1936 [==============================] - 7s 4ms/step - loss: 10.8764 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 10.8631 - val_loss: 2.5405 - val_Encoder-Garbedge_loss: 0.0098 - val_Encoder-Output_loss: 2.5307\n",
      "Train on 4712 samples, validate on 249 samples\n",
      "Epoch 9381/9381\n",
      "4712/4712 [==============================] - 17s 4ms/step - loss: 6.8871 - Encoder-Garbedge_loss: 0.0128 - Encoder-Output_loss: 6.8742 - val_loss: 1.6485 - val_Encoder-Garbedge_loss: 0.0103 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 4750 samples, validate on 251 samples\n",
      "Epoch 9401/9401\n",
      "4750/4750 [==============================] - 17s 4ms/step - loss: 7.9576 - Encoder-Garbedge_loss: 0.0137 - Encoder-Output_loss: 7.9439 - val_loss: 1.7416 - val_Encoder-Garbedge_loss: 0.0120 - val_Encoder-Output_loss: 1.7295\n",
      "Train on 5252 samples, validate on 277 samples\n",
      "Epoch 9421/9421\n",
      "5252/5252 [==============================] - 19s 4ms/step - loss: 6.0423 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.0290 - val_loss: 1.5571 - val_Encoder-Garbedge_loss: 0.0114 - val_Encoder-Output_loss: 1.5457\n",
      "Train on 4396 samples, validate on 232 samples\n",
      "Epoch 9441/9441\n",
      "4396/4396 [==============================] - 16s 4ms/step - loss: 6.8203 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.8068 - val_loss: 1.7733 - val_Encoder-Garbedge_loss: 0.0117 - val_Encoder-Output_loss: 1.7616\n",
      "Train on 4576 samples, validate on 241 samples\n",
      "Epoch 9461/9461\n",
      "4576/4576 [==============================] - 17s 4ms/step - loss: 7.0457 - Encoder-Garbedge_loss: 0.0138 - Encoder-Output_loss: 7.0319 - val_loss: 1.6181 - val_Encoder-Garbedge_loss: 0.0108 - val_Encoder-Output_loss: 1.6073\n",
      "Train on 5312 samples, validate on 280 samples\n",
      "Epoch 9481/9481\n",
      "5312/5312 [==============================] - 19s 4ms/step - loss: 6.0887 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.0755 - val_loss: 1.6488 - val_Encoder-Garbedge_loss: 0.0107 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 5139 samples, validate on 271 samples\n",
      "Epoch 9501/9501\n",
      "5139/5139 [==============================] - 18s 4ms/step - loss: 9.4456 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 9.4319 - val_loss: 1.8946 - val_Encoder-Garbedge_loss: 0.0092 - val_Encoder-Output_loss: 1.8854\n",
      "\n",
      "\n",
      "Train on 3935 samples, validate on 208 samples\n",
      "Epoch 9521/9521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3935/3935 [==============================] - 14s 4ms/step - loss: 6.9245 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 6.9113 - val_loss: 1.8660 - val_Encoder-Garbedge_loss: 0.0115 - val_Encoder-Output_loss: 1.8545\n",
      "Train on 4031 samples, validate on 213 samples\n",
      "Epoch 9541/9541\n",
      "4031/4031 [==============================] - 14s 4ms/step - loss: 7.1608 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.1477 - val_loss: 1.7112 - val_Encoder-Garbedge_loss: 0.0112 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 3729 samples, validate on 197 samples\n",
      "Epoch 9561/9561\n",
      "3729/3729 [==============================] - 13s 4ms/step - loss: 6.6064 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.5931 - val_loss: 1.7724 - val_Encoder-Garbedge_loss: 0.0106 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4362 samples, validate on 230 samples\n",
      "Epoch 9581/9581\n",
      "4362/4362 [==============================] - 15s 4ms/step - loss: 7.5594 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.5460 - val_loss: 1.7115 - val_Encoder-Garbedge_loss: 0.0115 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 3657 samples, validate on 193 samples\n",
      "Epoch 9601/9601\n",
      "3657/3657 [==============================] - 13s 4ms/step - loss: 9.0326 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 9.0191 - val_loss: 1.8392 - val_Encoder-Garbedge_loss: 0.0156 - val_Encoder-Output_loss: 1.8236\n",
      "Train on 4241 samples, validate on 224 samples\n",
      "Epoch 9621/9621\n",
      "4241/4241 [==============================] - 15s 4ms/step - loss: 6.7406 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 6.7275 - val_loss: 1.7406 - val_Encoder-Garbedge_loss: 0.0133 - val_Encoder-Output_loss: 1.7273\n",
      "Train on 2373 samples, validate on 125 samples\n",
      "Epoch 9641/9641\n",
      "2373/2373 [==============================] - 8s 4ms/step - loss: 5.4053 - Encoder-Garbedge_loss: 0.0129 - Encoder-Output_loss: 5.3925 - val_loss: 2.1987 - val_Encoder-Garbedge_loss: 0.0169 - val_Encoder-Output_loss: 2.1818\n",
      "Train on 4390 samples, validate on 232 samples\n",
      "Epoch 9661/9661\n",
      "4390/4390 [==============================] - 16s 4ms/step - loss: 7.6026 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.5893 - val_loss: 1.9004 - val_Encoder-Garbedge_loss: 0.0146 - val_Encoder-Output_loss: 1.8858\n",
      "Train on 4099 samples, validate on 216 samples\n",
      "Epoch 9681/9681\n",
      "4099/4099 [==============================] - 15s 4ms/step - loss: 7.6184 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.6049 - val_loss: 1.6838 - val_Encoder-Garbedge_loss: 0.0147 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 9701/9701\n",
      "4006/4006 [==============================] - 14s 4ms/step - loss: 9.2044 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 9.1913 - val_loss: 1.7420 - val_Encoder-Garbedge_loss: 0.0111 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 4707 samples, validate on 248 samples\n",
      "Epoch 9721/9721\n",
      "4707/4707 [==============================] - 17s 4ms/step - loss: 6.6011 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.5878 - val_loss: 1.7444 - val_Encoder-Garbedge_loss: 0.0134 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 2228 samples, validate on 118 samples\n",
      "Epoch 9741/9741\n",
      "2228/2228 [==============================] - 8s 4ms/step - loss: 9.6264 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 9.6131 - val_loss: 1.8955 - val_Encoder-Garbedge_loss: 0.0101 - val_Encoder-Output_loss: 1.8854\n",
      "Train on 4584 samples, validate on 242 samples\n",
      "Epoch 9761/9761\n",
      "4584/4584 [==============================] - 16s 4ms/step - loss: 6.5175 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.5042 - val_loss: 2.1926 - val_Encoder-Garbedge_loss: 0.0130 - val_Encoder-Output_loss: 2.1796\n",
      "Train on 4290 samples, validate on 226 samples\n",
      "Epoch 9781/9781\n",
      "4290/4290 [==============================] - 15s 4ms/step - loss: 7.0991 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.0857 - val_loss: 2.0505 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 2.0400\n",
      "Train on 3598 samples, validate on 190 samples\n",
      "Epoch 9801/9801\n",
      "3598/3598 [==============================] - 13s 4ms/step - loss: 6.6136 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 6.6005 - val_loss: 1.8060 - val_Encoder-Garbedge_loss: 0.0132 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 4768 samples, validate on 251 samples\n",
      "Epoch 9821/9821\n",
      "4768/4768 [==============================] - 17s 4ms/step - loss: 7.2306 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.2174 - val_loss: 1.9298 - val_Encoder-Garbedge_loss: 0.0134 - val_Encoder-Output_loss: 1.9164\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 9841/9841\n",
      "4006/4006 [==============================] - 14s 4ms/step - loss: 8.9736 - Encoder-Garbedge_loss: 0.0129 - Encoder-Output_loss: 8.9608 - val_loss: 1.6493 - val_Encoder-Garbedge_loss: 0.0111 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 3825 samples, validate on 202 samples\n",
      "Epoch 9861/9861\n",
      "3825/3825 [==============================] - 14s 4ms/step - loss: 7.6136 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.6005 - val_loss: 1.5895 - val_Encoder-Garbedge_loss: 0.0131 - val_Encoder-Output_loss: 1.5763\n",
      "Train on 5114 samples, validate on 270 samples\n",
      "Epoch 9881/9881\n",
      "5114/5114 [==============================] - 18s 4ms/step - loss: 7.6712 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.6581 - val_loss: 1.8045 - val_Encoder-Garbedge_loss: 0.0118 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 4485 samples, validate on 237 samples\n",
      "Epoch 9901/9901\n",
      "4485/4485 [==============================] - 16s 4ms/step - loss: 7.1919 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.1784 - val_loss: 1.8067 - val_Encoder-Garbedge_loss: 0.0140 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 5190 samples, validate on 274 samples\n",
      "Epoch 9921/9921\n",
      "5190/5190 [==============================] - 18s 4ms/step - loss: 7.1984 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.1853 - val_loss: 1.8380 - val_Encoder-Garbedge_loss: 0.0143 - val_Encoder-Output_loss: 1.8237\n",
      "Train on 3797 samples, validate on 200 samples\n",
      "Epoch 9941/9941\n",
      "3797/3797 [==============================] - 14s 4ms/step - loss: 5.8951 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 5.8819 - val_loss: 1.6838 - val_Encoder-Garbedge_loss: 0.0148 - val_Encoder-Output_loss: 1.6690\n",
      "Train on 4964 samples, validate on 262 samples\n",
      "Epoch 9961/9961\n",
      "4964/4964 [==============================] - 18s 4ms/step - loss: 5.6540 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 5.6404 - val_loss: 1.9698 - val_Encoder-Garbedge_loss: 0.0130 - val_Encoder-Output_loss: 1.9568\n",
      "Train on 5469 samples, validate on 288 samples\n",
      "Epoch 9981/9981\n",
      "5469/5469 [==============================] - 19s 4ms/step - loss: 7.0343 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 7.0207 - val_loss: 1.7178 - val_Encoder-Garbedge_loss: 0.0178 - val_Encoder-Output_loss: 1.7000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 10\n",
      "**********************************\n",
      "\n",
      "Train on 4323 samples, validate on 228 samples\n",
      "Epoch 10001/10001\n",
      "4323/4323 [==============================] - 15s 4ms/step - loss: 6.7877 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.7744 - val_loss: 1.7415 - val_Encoder-Garbedge_loss: 0.0106 - val_Encoder-Output_loss: 1.7309\n",
      "\n",
      "\n",
      "Train on 2870 samples, validate on 152 samples\n",
      "Epoch 10021/10021\n",
      "2870/2870 [==============================] - 10s 4ms/step - loss: 10.3873 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 10.3743 - val_loss: 1.8056 - val_Encoder-Garbedge_loss: 0.0129 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 5088 samples, validate on 268 samples\n",
      "Epoch 10041/10041\n",
      "5088/5088 [==============================] - 18s 4ms/step - loss: 7.5692 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 7.5556 - val_loss: 1.8656 - val_Encoder-Garbedge_loss: 0.0111 - val_Encoder-Output_loss: 1.8545\n",
      "Train on 4287 samples, validate on 226 samples\n",
      "Epoch 10061/10061\n",
      "4287/4287 [==============================] - 15s 4ms/step - loss: 9.3688 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 9.3555 - val_loss: 1.6166 - val_Encoder-Garbedge_loss: 0.0093 - val_Encoder-Output_loss: 1.6073\n",
      "Train on 3027 samples, validate on 160 samples\n",
      "Epoch 10081/10081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3027/3027 [==============================] - 11s 4ms/step - loss: 8.1489 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 8.1355 - val_loss: 1.8059 - val_Encoder-Garbedge_loss: 0.0127 - val_Encoder-Output_loss: 1.7932\n",
      "Train on 4067 samples, validate on 215 samples\n",
      "Epoch 10101/10101\n",
      "4067/4067 [==============================] - 14s 4ms/step - loss: 7.1745 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.1613 - val_loss: 1.6528 - val_Encoder-Garbedge_loss: 0.0146 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 5628 samples, validate on 297 samples\n",
      "Epoch 10121/10121\n",
      "5628/5628 [==============================] - 20s 4ms/step - loss: 8.0830 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 8.0695 - val_loss: 1.7673 - val_Encoder-Garbedge_loss: 0.0134 - val_Encoder-Output_loss: 1.7539\n",
      "Train on 4883 samples, validate on 257 samples\n",
      "Epoch 10141/10141\n",
      "4883/4883 [==============================] - 18s 4ms/step - loss: 7.6179 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.6044 - val_loss: 1.6503 - val_Encoder-Garbedge_loss: 0.0121 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 4391 samples, validate on 232 samples\n",
      "Epoch 10161/10161\n",
      "4391/4391 [==============================] - 16s 4ms/step - loss: 5.7451 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 5.7319 - val_loss: 2.6556 - val_Encoder-Garbedge_loss: 0.0125 - val_Encoder-Output_loss: 2.6430\n",
      "Train on 5474 samples, validate on 289 samples\n",
      "Epoch 10181/10181\n",
      "5474/5474 [==============================] - 20s 4ms/step - loss: 7.2959 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.2827 - val_loss: 1.6863 - val_Encoder-Garbedge_loss: 0.0172 - val_Encoder-Output_loss: 1.6690\n",
      "Train on 4681 samples, validate on 247 samples\n",
      "Epoch 10201/10201\n",
      "4681/4681 [==============================] - 17s 4ms/step - loss: 6.4013 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.3882 - val_loss: 1.7787 - val_Encoder-Garbedge_loss: 0.0169 - val_Encoder-Output_loss: 1.7618\n",
      "Train on 4414 samples, validate on 233 samples\n",
      "Epoch 10221/10221\n",
      "4414/4414 [==============================] - 16s 4ms/step - loss: 7.6003 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.5871 - val_loss: 1.7449 - val_Encoder-Garbedge_loss: 0.0140 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 6049 samples, validate on 319 samples\n",
      "Epoch 10241/10241\n",
      "6049/6049 [==============================] - 22s 4ms/step - loss: 8.4141 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 8.4007 - val_loss: 1.8096 - val_Encoder-Garbedge_loss: 0.0143 - val_Encoder-Output_loss: 1.7954\n",
      "Train on 4440 samples, validate on 234 samples\n",
      "Epoch 10261/10261\n",
      "4440/4440 [==============================] - 16s 4ms/step - loss: 6.3504 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.3370 - val_loss: 1.6797 - val_Encoder-Garbedge_loss: 0.0107 - val_Encoder-Output_loss: 1.6690\n",
      "Train on 4445 samples, validate on 234 samples\n",
      "Epoch 10281/10281\n",
      "4445/4445 [==============================] - 16s 4ms/step - loss: 7.4494 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 7.4359 - val_loss: 1.9007 - val_Encoder-Garbedge_loss: 0.0154 - val_Encoder-Output_loss: 1.8853\n",
      "Train on 4634 samples, validate on 244 samples\n",
      "Epoch 10301/10301\n",
      "4634/4634 [==============================] - 17s 4ms/step - loss: 7.2282 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.2149 - val_loss: 2.1224 - val_Encoder-Garbedge_loss: 0.0129 - val_Encoder-Output_loss: 2.1096\n",
      "Train on 3845 samples, validate on 203 samples\n",
      "Epoch 10321/10321\n",
      "3845/3845 [==============================] - 14s 4ms/step - loss: 6.8149 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 6.8018 - val_loss: 1.6836 - val_Encoder-Garbedge_loss: 0.0145 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 4028 samples, validate on 212 samples\n",
      "Epoch 10341/10341\n",
      "4028/4028 [==============================] - 14s 4ms/step - loss: 8.0845 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 8.0709 - val_loss: 1.7414 - val_Encoder-Garbedge_loss: 0.0106 - val_Encoder-Output_loss: 1.7308\n",
      "Train on 1936 samples, validate on 102 samples\n",
      "Epoch 10361/10361\n",
      "1936/1936 [==============================] - 7s 4ms/step - loss: 10.8925 - Encoder-Garbedge_loss: 0.0139 - Encoder-Output_loss: 10.8786 - val_loss: 2.0196 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 2.0090\n",
      "Train on 4712 samples, validate on 249 samples\n",
      "Epoch 10381/10381\n",
      "4712/4712 [==============================] - 17s 4ms/step - loss: 6.9207 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 6.9077 - val_loss: 1.6250 - val_Encoder-Garbedge_loss: 0.0111 - val_Encoder-Output_loss: 1.6138\n",
      "Train on 4750 samples, validate on 251 samples\n",
      "Epoch 10401/10401\n",
      "4750/4750 [==============================] - 17s 4ms/step - loss: 7.9553 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.9420 - val_loss: 1.5921 - val_Encoder-Garbedge_loss: 0.0126 - val_Encoder-Output_loss: 1.5796\n",
      "Train on 5252 samples, validate on 277 samples\n",
      "Epoch 10421/10421\n",
      "5252/5252 [==============================] - 19s 4ms/step - loss: 6.1098 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.0965 - val_loss: 1.7103 - val_Encoder-Garbedge_loss: 0.0104 - val_Encoder-Output_loss: 1.6999\n",
      "Train on 4396 samples, validate on 232 samples\n",
      "Epoch 10441/10441\n",
      "4396/4396 [==============================] - 16s 4ms/step - loss: 6.7063 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 6.6928 - val_loss: 1.6198 - val_Encoder-Garbedge_loss: 0.0126 - val_Encoder-Output_loss: 1.6073\n",
      "Train on 4576 samples, validate on 241 samples\n",
      "Epoch 10461/10461\n",
      "4576/4576 [==============================] - 17s 4ms/step - loss: 6.9590 - Encoder-Garbedge_loss: 0.0140 - Encoder-Output_loss: 6.9450 - val_loss: 1.5580 - val_Encoder-Garbedge_loss: 0.0125 - val_Encoder-Output_loss: 1.5455\n",
      "Train on 5312 samples, validate on 280 samples\n",
      "Epoch 10481/10481\n",
      "5312/5312 [==============================] - 19s 4ms/step - loss: 6.0755 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.0620 - val_loss: 1.5884 - val_Encoder-Garbedge_loss: 0.0120 - val_Encoder-Output_loss: 1.5763\n",
      "Train on 5139 samples, validate on 271 samples\n",
      "Epoch 10501/10501\n",
      "5139/5139 [==============================] - 18s 4ms/step - loss: 9.1310 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 9.1174 - val_loss: 1.9134 - val_Encoder-Garbedge_loss: 0.0122 - val_Encoder-Output_loss: 1.9012\n",
      "\n",
      "\n",
      "Train on 3935 samples, validate on 208 samples\n",
      "Epoch 10521/10521\n",
      "3935/3935 [==============================] - 14s 4ms/step - loss: 6.9454 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.9320 - val_loss: 1.8996 - val_Encoder-Garbedge_loss: 0.0141 - val_Encoder-Output_loss: 1.8854\n",
      "Train on 4031 samples, validate on 213 samples\n",
      "Epoch 10541/10541\n",
      "4031/4031 [==============================] - 14s 4ms/step - loss: 7.1240 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.1106 - val_loss: 1.7406 - val_Encoder-Garbedge_loss: 0.0097 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 3729 samples, validate on 197 samples\n",
      "Epoch 10561/10561\n",
      "3729/3729 [==============================] - 13s 4ms/step - loss: 6.5169 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 6.5036 - val_loss: 1.7747 - val_Encoder-Garbedge_loss: 0.0130 - val_Encoder-Output_loss: 1.7617\n",
      "Train on 4362 samples, validate on 230 samples\n",
      "Epoch 10581/10581\n",
      "4362/4362 [==============================] - 16s 4ms/step - loss: 7.5839 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.5707 - val_loss: 2.2455 - val_Encoder-Garbedge_loss: 0.0103 - val_Encoder-Output_loss: 2.2352\n",
      "Train on 3657 samples, validate on 193 samples\n",
      "Epoch 10601/10601\n",
      "3657/3657 [==============================] - 13s 4ms/step - loss: 9.0087 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 8.9953 - val_loss: 1.8691 - val_Encoder-Garbedge_loss: 0.0146 - val_Encoder-Output_loss: 1.8545\n",
      "Train on 4241 samples, validate on 224 samples\n",
      "Epoch 10621/10621\n",
      "4241/4241 [==============================] - 15s 4ms/step - loss: 6.7944 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.7810 - val_loss: 1.7474 - val_Encoder-Garbedge_loss: 0.0165 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 2373 samples, validate on 125 samples\n",
      "Epoch 10641/10641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2373/2373 [==============================] - 8s 4ms/step - loss: 5.4181 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 5.4048 - val_loss: 1.6856 - val_Encoder-Garbedge_loss: 0.0166 - val_Encoder-Output_loss: 1.6690\n",
      "Train on 4390 samples, validate on 232 samples\n",
      "Epoch 10661/10661\n",
      "4390/4390 [==============================] - 16s 4ms/step - loss: 7.5414 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.5280 - val_loss: 1.6493 - val_Encoder-Garbedge_loss: 0.0111 - val_Encoder-Output_loss: 1.6382\n",
      "Train on 4099 samples, validate on 216 samples\n",
      "Epoch 10681/10681\n",
      "4099/4099 [==============================] - 15s 4ms/step - loss: 7.6620 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.6486 - val_loss: 1.8033 - val_Encoder-Garbedge_loss: 0.0103 - val_Encoder-Output_loss: 1.7931\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 10701/10701\n",
      "4006/4006 [==============================] - 14s 4ms/step - loss: 9.1917 - Encoder-Garbedge_loss: 0.0136 - Encoder-Output_loss: 9.1781 - val_loss: 1.7431 - val_Encoder-Garbedge_loss: 0.0122 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 4707 samples, validate on 248 samples\n",
      "Epoch 10721/10721\n",
      "4707/4707 [==============================] - 19s 4ms/step - loss: 6.5090 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 6.4955 - val_loss: 1.7423 - val_Encoder-Garbedge_loss: 0.0114 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 2228 samples, validate on 118 samples\n",
      "Epoch 10741/10741\n",
      "2228/2228 [==============================] - 9s 4ms/step - loss: 9.4980 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 9.4846 - val_loss: 1.7414 - val_Encoder-Garbedge_loss: 0.0105 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 4584 samples, validate on 242 samples\n",
      "Epoch 10761/10761\n",
      "4584/4584 [==============================] - 18s 4ms/step - loss: 6.6320 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.6189 - val_loss: 1.7113 - val_Encoder-Garbedge_loss: 0.0113 - val_Encoder-Output_loss: 1.7000\n",
      "Train on 4290 samples, validate on 226 samples\n",
      "Epoch 10781/10781\n",
      "4290/4290 [==============================] - 17s 4ms/step - loss: 6.9992 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.9858 - val_loss: 1.9604 - val_Encoder-Garbedge_loss: 0.0131 - val_Encoder-Output_loss: 1.9473\n",
      "Train on 3598 samples, validate on 190 samples\n",
      "Epoch 10801/10801\n",
      "3598/3598 [==============================] - 14s 4ms/step - loss: 6.5580 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 6.5448 - val_loss: 1.8066 - val_Encoder-Garbedge_loss: 0.0139 - val_Encoder-Output_loss: 1.7927\n",
      "Train on 4768 samples, validate on 251 samples\n",
      "Epoch 10821/10821\n",
      "4768/4768 [==============================] - 17s 4ms/step - loss: 7.1136 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.1004 - val_loss: 1.9266 - val_Encoder-Garbedge_loss: 0.0103 - val_Encoder-Output_loss: 1.9163\n",
      "Train on 4006 samples, validate on 211 samples\n",
      "Epoch 10841/10841\n",
      "4006/4006 [==============================] - 15s 4ms/step - loss: 9.0129 - Encoder-Garbedge_loss: 0.0130 - Encoder-Output_loss: 8.9999 - val_loss: 1.6200 - val_Encoder-Garbedge_loss: 0.0127 - val_Encoder-Output_loss: 1.6073\n",
      "Train on 3825 samples, validate on 202 samples\n",
      "Epoch 10861/10861\n",
      "3825/3825 [==============================] - 14s 4ms/step - loss: 7.6742 - Encoder-Garbedge_loss: 0.0135 - Encoder-Output_loss: 7.6607 - val_loss: 1.6828 - val_Encoder-Garbedge_loss: 0.0137 - val_Encoder-Output_loss: 1.6691\n",
      "Train on 5114 samples, validate on 270 samples\n",
      "Epoch 10881/10881\n",
      "5114/5114 [==============================] - 21s 4ms/step - loss: 7.7326 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 7.7195 - val_loss: 1.8450 - val_Encoder-Garbedge_loss: 0.0114 - val_Encoder-Output_loss: 1.8337\n",
      "Train on 4485 samples, validate on 237 samples\n",
      "Epoch 10901/10901\n",
      "4485/4485 [==============================] - 18s 4ms/step - loss: 7.0664 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 7.0530 - val_loss: 1.7466 - val_Encoder-Garbedge_loss: 0.0157 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 5190 samples, validate on 274 samples\n",
      "Epoch 10921/10921\n",
      "5190/5190 [==============================] - 21s 4ms/step - loss: 7.2093 - Encoder-Garbedge_loss: 0.0131 - Encoder-Output_loss: 7.1962 - val_loss: 1.7554 - val_Encoder-Garbedge_loss: 0.0107 - val_Encoder-Output_loss: 1.7447\n",
      "Train on 3797 samples, validate on 200 samples\n",
      "Epoch 10941/10941\n",
      "3797/3797 [==============================] - 15s 4ms/step - loss: 5.9700 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 5.9569 - val_loss: 1.7460 - val_Encoder-Garbedge_loss: 0.0151 - val_Encoder-Output_loss: 1.7309\n",
      "Train on 4964 samples, validate on 262 samples\n",
      "Epoch 10961/10961\n",
      "4964/4964 [==============================] - 19s 4ms/step - loss: 5.6010 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 5.5876 - val_loss: 1.8668 - val_Encoder-Garbedge_loss: 0.0123 - val_Encoder-Output_loss: 1.8545\n",
      "Train on 5469 samples, validate on 288 samples\n",
      "Epoch 10981/10981\n",
      "5469/5469 [==============================] - 21s 4ms/step - loss: 6.8777 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.8643 - val_loss: 6.3818 - val_Encoder-Garbedge_loss: 0.0136 - val_Encoder-Output_loss: 6.3682\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 11\n",
      "**********************************\n",
      "\n",
      "Train on 4323 samples, validate on 228 samples\n",
      "Epoch 11001/11001\n",
      "4323/4323 [==============================] - 17s 4ms/step - loss: 6.7921 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 6.7786 - val_loss: 1.8051 - val_Encoder-Garbedge_loss: 0.0113 - val_Encoder-Output_loss: 1.7938\n",
      "\n",
      "\n",
      "Train on 2870 samples, validate on 152 samples\n",
      "Epoch 11021/11021\n",
      "2870/2870 [==============================] - 11s 4ms/step - loss: 10.4690 - Encoder-Garbedge_loss: 0.0132 - Encoder-Output_loss: 10.4558 - val_loss: 1.8968 - val_Encoder-Garbedge_loss: 0.0113 - val_Encoder-Output_loss: 1.8855\n",
      "Train on 5088 samples, validate on 268 samples\n",
      "Epoch 11041/11041\n",
      "5088/5088 [==============================] - 20s 4ms/step - loss: 7.4416 - Encoder-Garbedge_loss: 0.0133 - Encoder-Output_loss: 7.4283 - val_loss: 2.4769 - val_Encoder-Garbedge_loss: 0.0096 - val_Encoder-Output_loss: 2.4673\n",
      "Train on 4287 samples, validate on 226 samples\n",
      "Epoch 11061/11061\n",
      "4287/4287 [==============================] - 17s 4ms/step - loss: 9.3235 - Encoder-Garbedge_loss: 0.0134 - Encoder-Output_loss: 9.3101 - val_loss: 1.6918 - val_Encoder-Garbedge_loss: 0.0113 - val_Encoder-Output_loss: 1.6805\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-aa995532c04e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                 )\n\u001b[0;32m     47\u001b[0m             \u001b[0mn\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "#n=0\n",
    "#e=1\n",
    "for d in range(1,20):\n",
    "    start=1\n",
    "    print('Epoch: '+str(d)+'\\n'+\"**********************************\\n\")\n",
    "    for i in range(200):\n",
    "        vectors_train = np.load('D:/112/decoder/Data/data3000/news_vectors'+str(999-i)+'.npy')\n",
    "        #print(start)\n",
    "        texts = textreader(start)\n",
    "        start+=500\n",
    "        #print(len(texts))\n",
    "\n",
    "        for j in range(5):\n",
    "            tt, kol  = word_vectors_creator(texts[0+j*100:(1+j)*100])\n",
    "            vtt = vectorsextender(vectors_train[0+j*100:(1+j)*100], kol)\n",
    "            pos = positioncreator(kol)\n",
    "            tt, vtt,pos = shuffle(tt, vtt,pos, random_state=0)\n",
    "\n",
    "            if n%20==0:\n",
    "                model.fit(\n",
    "                    x=[vtt,\n",
    "                       pos],\n",
    "                    y = [vtt,\n",
    "                        tt],\n",
    "                    epochs=e, initial_epoch=n,\n",
    "                    validation_split=0.05,\n",
    "                    verbose=1,\n",
    "                    batch_size=4\n",
    "                )\n",
    "                if n%500==0:\n",
    "                    model.save('D:/112/decoder/models/mse_sen_to_word'+str(d)+'_'+str(i)+'.h5')\n",
    "                    print('\\n')\n",
    "            else:\n",
    "                model.fit(\n",
    "                    x=[vtt,\n",
    "                       pos],\n",
    "                    y = [vtt,\n",
    "                        tt],\n",
    "                    epochs=e, initial_epoch=n,\n",
    "                    validation_split=0.05,\n",
    "                    verbose=0,\n",
    "                    batch_size=4\n",
    "                )\n",
    "            n+=1\n",
    "            e+=1\n",
    "    model.save('D:/112/decoder/models/mse_sen_to_word'+str(d)+'.h5')\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/decoder/models/sen_to_word'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
