{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras_transformer import *\n",
    "\n",
    "import numpy as np\n",
    "from keras_layer_normalization import LayerNormalization\n",
    "from keras_multi_head import MultiHeadAttention\n",
    "from keras_position_wise_feed_forward import FeedForward\n",
    "from keras_pos_embd import TrigPosEmbedding\n",
    "from keras_embed_sim import EmbeddingRet, EmbeddingSim\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.layers import Input, Lambda,RepeatVector,Dense,Reshape,Dropout,Concatenate\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "\n",
    "class MModel:    \n",
    "    @staticmethod\n",
    "    def loadmodel(is_decoder,path=''):\n",
    "        if is_decoder:\n",
    "            model = MModel.get_m(\n",
    "                token_num=3003,\n",
    "                embed_dim=100,\n",
    "                encoder_num=3,\n",
    "                decoder_num=6,\n",
    "                head_num=4,\n",
    "                hidden_dim=120,\n",
    "                attention_activation='relu',\n",
    "                feed_forward_activation='relu',\n",
    "                dropout_rate=0.05,\n",
    "                embed_weights=np.random.random((3003, 100)),\n",
    "                use_adapter=False,\n",
    "            )\n",
    "            if path!='':\n",
    "                model.load_weights(path)\n",
    "            model.compile(\n",
    "                optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "            )    \n",
    "            return model\n",
    "        else:\n",
    "            model = MModel.get_dense_encoder()\n",
    "            if path!='':\n",
    "                model.load_weights(path)\n",
    "            model.compile(\n",
    "                optimizer='adam',\n",
    "                loss='mean_absolute_error',\n",
    "            )    \n",
    "            return model\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_m(token_num,\n",
    "          embed_dim,\n",
    "          encoder_num,\n",
    "          decoder_num,\n",
    "          head_num,\n",
    "          hidden_dim,\n",
    "          attention_activation=None,\n",
    "          feed_forward_activation='relu',\n",
    "          dropout_rate=0.0,\n",
    "          embed_weights =None,\n",
    "          embed_trainable=None,\n",
    "          trainable=True,\n",
    "          use_adapter=False,\n",
    "          adapter_units=None,\n",
    "          adapter_activation='relu'):\n",
    "\n",
    "        decoder_token_num = token_num\n",
    "\n",
    "        decoder_embed_weights = embed_weights\n",
    "\n",
    "        if decoder_embed_weights is not None:\n",
    "            decoder_embed_weights = [decoder_embed_weights]\n",
    "\n",
    "        decoder_embed_trainable = embed_trainable\n",
    "\n",
    "        if decoder_embed_trainable is None:\n",
    "            decoder_embed_trainable = decoder_embed_weights is None\n",
    "\n",
    "\n",
    "        decoder_embed_layer = EmbeddingRet(\n",
    "            input_dim=decoder_token_num,\n",
    "            output_dim=embed_dim,\n",
    "            mask_zero=True,\n",
    "            weights=decoder_embed_weights,\n",
    "            trainable=decoder_embed_trainable,\n",
    "            name='Decoder-Token-Embedding',\n",
    "        )\n",
    "\n",
    "        encoder_input = keras.layers.Input(shape=(None,100), name='Encoder-Input')\n",
    "        pos_wised_encoder = TrigPosEmbedding(\n",
    "            mode=TrigPosEmbedding.MODE_ADD,\n",
    "            name='Encoder-Embedding',\n",
    "        )(encoder_input)\n",
    "\n",
    "        encoded_layer = get_encoders(\n",
    "            encoder_num=encoder_num,\n",
    "            input_layer=pos_wised_encoder,\n",
    "            head_num=head_num,\n",
    "            hidden_dim=hidden_dim,\n",
    "            attention_activation=attention_activation,\n",
    "            feed_forward_activation=feed_forward_activation,\n",
    "            dropout_rate=dropout_rate,\n",
    "            trainable=trainable,\n",
    "            use_adapter=use_adapter,\n",
    "            adapter_units=adapter_units,\n",
    "            adapter_activation=adapter_activation,\n",
    "        )\n",
    "\n",
    "        decoder_input = keras.layers.Input(shape=(None,), name='Decoder-Input') \n",
    "        decoder_embed, decoder_embed_weights = decoder_embed_layer(decoder_input)\n",
    "        decoder_embed = TrigPosEmbedding(\n",
    "            mode=TrigPosEmbedding.MODE_ADD,\n",
    "            name='Decoder-Embedding',\n",
    "        )(decoder_embed)\n",
    "        decoded_layer = get_decoders(\n",
    "            decoder_num=decoder_num,\n",
    "            input_layer=decoder_embed,\n",
    "            encoded_layer=encoded_layer,\n",
    "            head_num=head_num,\n",
    "            hidden_dim=hidden_dim,\n",
    "            attention_activation=attention_activation,\n",
    "            feed_forward_activation=feed_forward_activation,\n",
    "            dropout_rate=dropout_rate,\n",
    "            trainable=trainable,\n",
    "            use_adapter=use_adapter,\n",
    "            adapter_units=adapter_units,\n",
    "            adapter_activation=adapter_activation,\n",
    "        )\n",
    "        dense_layer = EmbeddingSim(\n",
    "            trainable=trainable,\n",
    "            name='Output',\n",
    "        )([decoded_layer, decoder_embed_weights])\n",
    "        return keras.models.Model(inputs=[encoder_input,decoder_input], outputs=dense_layer)\n",
    "    \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_dense_encoder():\n",
    "        vector = Input(shape=(512,), name='Vectors-Input',dtype='float32')\n",
    "        vector_shiter = Dense(512)(vector)\n",
    "        position = Input(shape=(1,), name='Positions-Input',dtype='int32')\n",
    "        categorical_position=Lambda(MModel.to_cat, name='Positional_encoding')(position)\n",
    "        reshaped_categorical_position=Reshape((512,))(categorical_position)\n",
    "        concatenated_encoder_input=Concatenate()([vector,reshaped_categorical_position])\n",
    "        encoder_input_divider1 = Dense(1024, name='Encoder-Output-Divider-1',activation='selu')(concatenated_encoder_input)\n",
    "        encoder_input_dropout1=Dropout(0.1, name='Encoder-Output-Dropout-1')(encoder_input_divider1)\n",
    "\n",
    "        encoder_input_divider2 = Dense(512, name='Encoder-Output-Divider-2',activation='selu')(encoder_input_dropout1)\n",
    "        encoder_input_dropout2=Dropout(0.1, name='Encoder-Output-Dropout-2')(encoder_input_divider2)\n",
    "\n",
    "        output_vector = Dense(512, name='Encoder-Garbedge',activation='selu')(encoder_input_dropout2)\n",
    "        encoder_input_divider3 = Dense(256, name='Encoder-Output-Divider-3',activation='selu')(encoder_input_dropout2)\n",
    "\n",
    "        output_vector2 = Dense(100, name='Encoder-Output',activation='selu')(encoder_input_divider3)\n",
    "\n",
    "        return Model(inputs=[vector,position],outputs=[output_vector,output_vector2])\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def to_cat(y):\n",
    "        from keras import backend as k\n",
    "        return k.one_hot(y, 512)\n",
    "  \n",
    "    @staticmethod\n",
    "    def reset_keras():\n",
    "        sess = K.get_session()\n",
    "        K.clear_session()\n",
    "        sess.close()\n",
    "        sess = K.get_session()\n",
    "\n",
    "        # use the same config as you used to create the session\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "        K.set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "    def __init__(self,is_decoder, path=''):\n",
    "        '''\n",
    "        k=0\n",
    "        if is_decoder:\n",
    "            k=0.75\n",
    "        else:\n",
    "            k=0.25\n",
    "        config = tf.ConfigProto(\n",
    "            gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=k)\n",
    "        )\n",
    "        '''\n",
    "        '''\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        config.log_device_placement = True\n",
    "        '''\n",
    "        #self.sess = tf.Session(config=config)\n",
    "        #K.set_session(self.sess)\n",
    "        self.model = self.loadmodel(is_decoder=is_decoder,path=path)\n",
    "        self.graph = tf.get_default_graph()\n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "        with self.graph.as_default():\n",
    "            result = self.model.predict(X)\n",
    "            return result\n",
    "            \n",
    "    def fit(self, X, Y, n_epochs, init_epoch):\n",
    "        with self.graph.as_default():\n",
    "            result = self.model.fit(x=X,y=Y, epochs=n_epochs, initial_epoch=init_epoch)\n",
    "            model.save('D:/112/decoder/models/dec_buf.h5')\n",
    "            return result\n",
    "            \n",
    "    def evaluate(self, X, Y):\n",
    "        with self.graph.as_default():\n",
    "            result = self.model.fit(x=X,y=Y)\n",
    "            return result\n",
    "    \n",
    "    def train_on_batch(self, X, Y):\n",
    "        with self.graph.as_default():\n",
    "            result = self.model.train_on_batch(x=X,y=Y)\n",
    "            model.save('D:/112/decoder/models/dec_buf.h5')\n",
    "            return result\n",
    "            \n",
    "    def test_on_batch(self, X, Y):\n",
    "        with self.graph.as_default():\n",
    "            result = self.model.test_on_batch(x=X,y=Y)\n",
    "            return result\n",
    "            \n",
    "    def predict_on_batch(self, X, Y):\n",
    "        with self.graph.as_default():\n",
    "            result = self.model.predict_on_batch(X)\n",
    "            return result\n",
    "            \n",
    "    def save(self, path):\n",
    "        self.model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def piecesextender(data):\n",
    "    kol= np.zeros(shape=(data.shape[0]))\n",
    "    for i in range(data.shape[0]):\n",
    "        kol[i]=np.count_nonzero(data[i])\n",
    "    kol = kol.astype(np.int)\n",
    "    out = np.zeros(shape=(np.sum(kol)-2*kol.shape[0],512))\n",
    "    buf = 0\n",
    "    for g in range(data.shape[0]):        \n",
    "        for k in range(1,kol[g]-1):\n",
    "            out[buf][0]=3000\n",
    "            out[buf][1:513-k]+=data[g][k:]\n",
    "            buf+=1\n",
    "    return out, kol\n",
    "\n",
    "def vectorsextender(data,kol):\n",
    "    out = np.zeros(shape=(np.sum(kol)-2*data.shape[0],512))\n",
    "    buf=0\n",
    "    for g in range(data.shape[0]):\n",
    "        for k in range(kol[g]-2):\n",
    "            out[buf]+=data[g]\n",
    "            buf+=1\n",
    "    return out\n",
    "\n",
    "def positionencoder(kol):\n",
    "    out = np.zeros(shape=(np.sum(kol)-2*kol.shape[0],1))\n",
    "    out = out.astype(np.int)\n",
    "    buf=0\n",
    "    for g in range(len(kol)):\n",
    "        for k in range(1,kol[g]-1):\n",
    "            out[buf]=k\n",
    "            buf+=1\n",
    "    return out\n",
    "\n",
    "def vectors_per_words(vectors,kols,model):\n",
    "    out = np.zeros(shape=(vectors.shape[0],512,100))\n",
    "    kol = kols.tolist()\n",
    "    for i in range(vectors.shape[0]):\n",
    "        out[i][kol[i][0]] = np.ones(100)\n",
    "        for k in range(kol[i][0]-1):\n",
    "            out[i][k+1]=model.predict(\n",
    "                [vectors_train[i].reshape(1,512),\n",
    "                 np.array([k+1])])[1]\n",
    "        out[i][kol[i][0]+2:]-= np.ones(shape=(512-kol[i][0]-2,100))\n",
    "        out[i][kol[i][0]+2:]-= np.ones(shape=(512-kol[i][0]-2,100))\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_shifter_model = MModel(is_decoder=False,path='D:/112/decoder/models/sen_to_word2_0.h5')\n",
    "#decoder = MModel(is_decoder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readed\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3492: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Converted\n",
      "19212\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[1640,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node Decoder-1-MultiHeadSelfAttention/Decoder-1-MultiHeadSelfAttention-Attention/sub}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss/mul/_3139]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[1640,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node Decoder-1-MultiHeadSelfAttention/Decoder-1-MultiHeadSelfAttention-Attention/sub}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-338f22bc5d05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m             X=[vpwt,\n\u001b[0;32m     40\u001b[0m                ptt],\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         )\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m#MModel.reset_keras()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-bb397e800a3c>\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/112/decoder/models/dec_buf.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1449\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1450\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dec2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dec2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[1640,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node Decoder-1-MultiHeadSelfAttention/Decoder-1-MultiHeadSelfAttention-Attention/sub}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss/mul/_3139]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[1640,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node Decoder-1-MultiHeadSelfAttention/Decoder-1-MultiHeadSelfAttention-Attention/sub}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "import gc\n",
    "\n",
    "for i in range(1000):\n",
    "    vectors_train = np.load('D:/112/decoder/data/data3000/news_vectors'+str(i)+'.npy')\n",
    "    pieces_train = np.load('D:/112/decoder/data/data3000/news_pieces'+str(i)+'.npy')\n",
    "    shifting = np.ones(shape=(pieces_train.shape[0],512))\n",
    "    pieces_train = pieces_train+shifting\n",
    "    \n",
    "    print('Readed')  \n",
    "        \n",
    "    for j in range(90):\n",
    "        ptt, kol = piecesextender(pieces_train[0+j*5:(1+j)*5])\n",
    "        pot = np.copy(ptt)\n",
    "        pot = shift(pot, (0,-1))\n",
    "        pot = pot.reshape(pot.shape[0],512,1)\n",
    "        vtt = vectorsextender(vectors_train[0+j*5:(1+j)*5], kol)\n",
    "        pos = positionencoder(kol)\n",
    "        encoder_shifter_model = MModel(is_decoder=False,path='D:/112/decoder/models/sen_to_word2_0.h5')\n",
    "        vpwt=vectors_per_words(vtt,pos,encoder_shifter_model)\n",
    "        #MModel.reset_keras()\n",
    "        print('Converted')\n",
    "                \n",
    "        sess = K.get_session()\n",
    "        K.clear_session()\n",
    "        sess.close()\n",
    "        sess = K.get_session()\n",
    "        try:\n",
    "            del encoder_shifter_model\n",
    "        except:\n",
    "            pass\n",
    "        print(gc.collect())\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "        K.set_session(tf.Session(config=config))\n",
    "        \n",
    "        model = MModel(is_decoder=True,path='D:/112/decoder/models/dec_buf.h5')     \n",
    "        model.train_on_batch(#MModel(is_decoder=True,path='D:/112/decoder/models/dec_buf.h5').train_on_batch(\n",
    "            X=[vpwt,\n",
    "               ptt],\n",
    "            Y = pot\n",
    "        )\n",
    "        #MModel.reset_keras()\n",
    "        sess = K.get_session()\n",
    "        K.clear_session()\n",
    "        sess.close()\n",
    "        sess = K.get_session()\n",
    "        try:\n",
    "            del encoder_shifter_model\n",
    "        except:\n",
    "            pass\n",
    "        print(gc.collect())\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "        K.set_session(tf.Session(config=config))\n",
    "        \n",
    "    ptt, kol = piecesextender(pieces_train[450:])\n",
    "    pot = np.copy(ptt)\n",
    "    pot = shift(pot, (0,-1))\n",
    "    pot = pot.reshape(pot.shape[0],512,1)\n",
    "    vtt = vectorsextender(vectors_train[450:], kol)\n",
    "    pos = positionencoder(kol)        \n",
    "    encoder_shifter_model = MModel(is_decoder=False,path='D:/112/decoder/models/sen_to_word2_0.h5')\n",
    "    vpwt=vectors_per_words(vtt,pos,encoder_shifter_model)\n",
    "\n",
    "    sess = K.get_session()\n",
    "    K.clear_session()\n",
    "    sess.close()\n",
    "    sess = K.get_session()\n",
    "    try:\n",
    "        del encoder_shifter_model\n",
    "    except:\n",
    "        pass\n",
    "    print(gc.collect())\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    K.set_session(tf.Session(config=config))\n",
    "\n",
    "    \n",
    "    model = MModel(is_decoder=True,path='D:/112/decoder/models/dec_buf.h5')     \n",
    "    model.train_on_batch(\n",
    "    #MModel(is_decoder=True,path='D:/112/decoder/models/dec_buf.h5').test_on_batch(\n",
    "        X=[vpwt,\n",
    "           ptt],\n",
    "        Y = pot\n",
    "    )\n",
    "     \n",
    "    model.save('D:/112/decoder/models/m'+str(i)+'.h5')\n",
    "    #MModel.reset_keras()\n",
    "    sess = K.get_session()\n",
    "    K.clear_session()\n",
    "    sess.close()\n",
    "    sess = K.get_session()\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        pass\n",
    "    print(gc.collect())\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
